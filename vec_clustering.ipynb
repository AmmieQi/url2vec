{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "# from random import randint\n",
    "from gensim.models import Word2Vec\n",
    "from url_sequences.sequence_manager import *\n",
    "from url_sequences.sequence_plotter import *\n",
    "from url_sequences.clustering_metrics import *\n",
    "\n",
    "import sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "import hdbscan\n",
    "\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "# from plotly.graph_objs import *\n",
    "from plotly.tools import FigureFactory as FF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_colors(n):\n",
    "    # 1.arancione, 2.bianco, 3.giallo, 4.azzurro, 5.verde, 6.blu, 7.fucsia, 8.viola\n",
    "    colors = [\"#FF8F00\", \"#FFFFFF\", \"#FFFF00\", \"#00E5FF\", \"#76FF03\", \"#2979FF\", \"#F50057\", \"#9C27B0\"]\n",
    "    c = \"\"\n",
    "    if n < 0:\n",
    "        c = \"#009688\"\n",
    "    elif n < len(colors):\n",
    "        c = colors[n]\n",
    "    else:\n",
    "        c = \"#\" + format(n**5, '06X')\n",
    "    return c\n",
    "\n",
    "# \"#\" + format(n + randint(0, 16777215 - n), '06X')\n",
    "# print get_colors(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORD2VEC MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = os.getcwd() + \"/dataset/cs.illinois.edu/RandomWalkLists-depth.100000.seqLen.10/\"\n",
    "rwwl_map_path = path + \"sequencesMapUrl.txt\"\n",
    "rwwl_seq_path = path + \"sequencesIDs.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# because of generator\n",
    "vocab_sequences = get_seq(rwwl_seq_path, 1)\n",
    "train_sequences = get_seq(rwwl_seq_path, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "890323"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model = Word2Vec(min_count=1)\n",
    "w2v_model.build_vocab(vocab_sequences)\n",
    "w2v_model.train(train_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE 2-DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq_map = get_seq_map(rwwl_map_path)\n",
    "\n",
    "# 100-dim vecs\n",
    "wordvecs = [w2v_model[key] for key in seq_map]\n",
    "hundred_dim_wordvecs = np.array(wordvecs, dtype=\"float64\")\n",
    "\n",
    "# long-url labels\n",
    "word_labels = [seq_map[key] for key in seq_map]\n",
    "\n",
    "# 2-dim vecs\n",
    "two_dimensioner = TSNE(n_components=2)\n",
    "\n",
    "# 2-dim vecs\n",
    "two_dim_wordvecs = two_dimensioner.fit_transform(hundred_dim_wordvecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters found with DBSCAN: 11\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, -1]\n"
     ]
    }
   ],
   "source": [
    "dbscan_clusterer = DBSCAN(eps=2.9, min_samples=10)\n",
    "dbscan_clusterer.fit(hundred_dim_wordvecs)\n",
    "\n",
    "dbscan_colors = [get_colors(n_clust) for n_clust in dbscan.labels_]\n",
    "\n",
    "print \"Clusters found with DBSCAN:\", len(set(dbscan.labels_))\n",
    "print [label for label in set(dbscan.labels_)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\"seamless=\"seamless\" src=\"https://plot.ly/~chrispol/41.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbscan_data = sc_plot(two_dim_wordvecs, word_labels, dbscan_colors)\n",
    "py.iplot(dbscan_data, filename='Word Vectors - Scatter plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDBSCAN CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters found with HDBSCAN: 7\n",
      "[0, 1, 2, 3, 4, 5, -1]\n"
     ]
    }
   ],
   "source": [
    "hdbscan_clusterer = hdbscan.HDBSCAN(min_cluster_size=13)\n",
    "hdbscan_labels = hdbscan_clusterer.fit_predict(hundred_dim_wordvecs)\n",
    "\n",
    "hdbscan_colors = [get_colors(n_clust) for n_clust in hdbscan_labels]\n",
    "\n",
    "print \"Clusters found with HDBSCAN:\", len(set(hdbscan_labels))\n",
    "print [label for label in set(hdbscan_labels)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDBSCAN PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\"seamless=\"seamless\" src=\"https://plot.ly/~chrispol/47.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdbscan_data = sc_plot(two_dim_wordvecs, word_labels, hdbscan_colors)\n",
    "py.iplot(hdbscan_data, filename='Word Vectors - Scatter plot HDBSCAN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-MEANS CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters found with K-MEANS: 8\n",
      "[0, 1, 2, 3, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "kmeans_clusterer = KMeans(n_clusters=8)\n",
    "kmeans_clusters = kmeans_clusterer.fit(hundred_dim_wordvecs)\n",
    "\n",
    "kmeans_colors = [get_colors(n_clust) for n_clust in kmeans_clusters.labels_]\n",
    "\n",
    "print \"Clusters found with K-MEANS:\", len(set(kmeans_clusters.labels_))\n",
    "print [label for label in set(kmeans_clusters.labels_)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-MEANS PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\"seamless=\"seamless\" src=\"https://plot.ly/~chrispol/49.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_data = sc_plot(two_dim_wordvecs, word_labels, kmeans_colors)\n",
    "py.iplot(kmeans_data, filename='Word Vectors - Scatter plot K-MEANS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MANUALLY CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters found manually: 8\n",
      "[0, 1, 2, 3, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "clusterized_map_path = path + \"sequencesMapUrl-manually-clusterized.txt\"\n",
    "seq_tuple_list = get_sequence_tuple_list(clusterized_map_path)\n",
    "\n",
    "# dict{url_code: cluster_membership} - manually clusterized\n",
    "real_cluster_membership = {tup[1].strip(): int(tup[2].strip()) for tup in seq_tuple_list}\n",
    "\n",
    "# dict{longurl: cluster_membership} - manually clusterized - never used\n",
    "real_cluster_longurl_membership = {tup[0].strip(): int(tup[2].strip()) for tup in seq_tuple_list}\n",
    "\n",
    "real_cluster_colors = [get_colors(real_cluster_membership[key]) for key in seq_map]\n",
    "\n",
    "print \"Clusters found manually:\", len(set(real_cluster_membership.values()))\n",
    "print [label for label in set(real_cluster_membership.values())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MANUALLY CLUSTERING - PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\"seamless=\"seamless\" src=\"https://plot.ly/~chrispol/45.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_cluster_data = sc_plot(two_dim_wordvecs, word_labels, real_cluster_colors)\n",
    "py.iplot(real_cluster_data, filename='Word Vectors - Scatter plot MANUALLY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.290719370491\n",
      "recall:     0.068281938326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/anaconda3/envs/python2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1203: DeprecationWarning:\n",
      "\n",
      "The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "\n",
      "/home/chris/anaconda3/envs/python2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1304: DeprecationWarning:\n",
      "\n",
      "The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using seq_map to keep the same order, dunno if it's right\n",
    "real_membership_list = [real_cluster_membership[key] for key in seq_map]\n",
    "    \n",
    "real_membership_list = np.array(real_clust, dtype=\"int32\")\n",
    "\n",
    "print \"precision: \", sklearn.metrics.precision_score(real_membership_list, kmeans_clusters.labels_)\n",
    "print \"recall:    \", sklearn.metrics.recall_score(real_membership_list, kmeans_clusters.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([0, 1, 2, 3, 4, 5, 6, 7]) set([0, 1, 2, 3, 4, 5, -1])\n",
      "[[  0   0   0  18   0   0  21]\n",
      " [  0   0  23  30   0   0  73]\n",
      " [  0  16   0   1   0   0  26]\n",
      " [  0   0   0  80  64  45  90]\n",
      " [ 15   0   0 -25   0   0  26]\n",
      " [  0   0   0  64   0   0  46]\n",
      " [  0   0   0   2   0   0  11]\n",
      " [  0   0   0   5   0   0  21]]\n"
     ]
    }
   ],
   "source": [
    "def get_confusion_table(real_membership_list, clusters_found_labels):\n",
    "    # matrix(num_of real_clusters x clusters_found)\n",
    "    conf_table = np.zeros((len(set(real_membership_list)), len(set(clusters_found_labels))), dtype=\"int8\")\n",
    "    real_clusters_set = set(real_membership_list)\n",
    "    # errore del -1\n",
    "    for current_clust in real_clusters_set:\n",
    "        for i in range(len(clusters_found_labels)):\n",
    "            if real_membership_list[i] == current_clust:\n",
    "                cluster_found = clusters_found_labels[i]\n",
    "                conf_table[current_clust][cluster_found] = conf_table[current_clust][cluster_found] + 1\n",
    "    return conf_table\n",
    "\n",
    "confusion_table = get_confusion_table(real_membership_list, hdbscan_labels)\n",
    "\n",
    "print set(real_membership_list), set(hdbscan_labels)\n",
    "print confusion_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['real clust' '0' '1' '2' '3' '4' '5' '6']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\"seamless=\"seamless\" src=\"https://plot.ly/~chrispol/51.embed\" height=\"290px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch = [c for c in range(len(set(hdbscan_labels)))]\n",
    "\n",
    "chh = [\"real clust\"] + ch\n",
    "col_headings = np.array(chh)\n",
    "print col_headings\n",
    "\n",
    "table = FF.create_table(confusion_table, index=True)\n",
    "py.iplot(table, filename='index_table')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
