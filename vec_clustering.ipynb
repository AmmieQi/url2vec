{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "# import seaborn as sns\n",
    "import numpy as np\n",
    "# from random import randint\n",
    "from gensim.models import Word2Vec\n",
    "from url_sequences.sequence_manager import *\n",
    "from url_sequences.sequence_handler import *\n",
    "from url_sequences.sequence_plotter import *\n",
    "from url_sequences.clustering_metrics import *\n",
    "\n",
    "import sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "import hdbscan\n",
    "\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "# from plotly.graph_objs import *\n",
    "from plotly.tools import FigureFactory as FF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORD2VEC MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = os.getcwd() + \"/dataset/depth-100k/seqLen-10/cs.illinois.eduRandomWalkLists.depth.100000.seqLen.10/\"\n",
    "rwwl_map_path = path + \"sequencesMapUrl.txt\"\n",
    "rwwl_seq_path = path + \"sequencesIDs.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# because of generator\n",
    "vocab_sequences = get_seq(rwwl_seq_path, 1)\n",
    "train_sequences = get_seq(rwwl_seq_path, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "890323"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model = Word2Vec(min_count=1, window=5, negative=5)\n",
    "w2v_model.build_vocab(vocab_sequences)\n",
    "w2v_model.train(train_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE 2-DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq_map = get_seq_map(rwwl_map_path)\n",
    "\n",
    "# 100-dim vecs\n",
    "wordvecs = [w2v_model[key] for key in seq_map]\n",
    "hundred_dim_wordvecs = np.array(wordvecs, dtype=\"float64\")\n",
    "\n",
    "# long-url labels\n",
    "word_labels = [seq_map[key] for key in seq_map]\n",
    "\n",
    "# 2-dim vecs\n",
    "two_dimensioner = TSNE(n_components=2)\n",
    "two_dim_wordvecs = two_dimensioner.fit_transform(hundred_dim_wordvecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters found with DBSCAN: 16\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, -1]\n"
     ]
    }
   ],
   "source": [
    "dbscan_clusterer = DBSCAN(eps=0.9, min_samples=4)\n",
    "dbscan_clusterer.fit(hundred_dim_wordvecs)\n",
    "\n",
    "dbscan_colors = [get_color(n_clust) for n_clust in dbscan_clusterer.labels_]\n",
    "\n",
    "print \"Clusters found with DBSCAN:\", len(set(dbscan_clusterer.labels_))\n",
    "print [label for label in set(dbscan_clusterer.labels_)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfuly sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~chrispolo/0 or inside your plot.ly account where it is named 'Word Vectors - Scatter plot DBSCAN'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\"seamless=\"seamless\" src=\"https://plot.ly/~chrispolo/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbscan_data = scatter_plot(two_dim_wordvecs, word_labels, dbscan_colors)\n",
    "py.iplot(dbscan_data, filename='Word Vectors - Scatter plot DBSCAN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDBSCAN CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters found with HDBSCAN: 16\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, -1]\n"
     ]
    }
   ],
   "source": [
    "hdbscan_clusterer = hdbscan.HDBSCAN(min_cluster_size=6)\n",
    "hdbscan_labels = hdbscan_clusterer.fit_predict(hundred_dim_wordvecs)\n",
    "\n",
    "hdbscan_colors = [get_color(n_clust) for n_clust in hdbscan_labels]\n",
    "\n",
    "print \"Clusters found with HDBSCAN:\", len(set(hdbscan_labels))\n",
    "print [label for label in set(hdbscan_labels)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDBSCAN PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hdbscan_data = scatter_plot(two_dim_wordvecs, word_labels, hdbscan_colors)\n",
    "py.iplot(hdbscan_data, filename='Word Vectors - Scatter plot HDBSCAN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-MEANS CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters found with K-MEANS: 15\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n"
     ]
    }
   ],
   "source": [
    "kmeans_clusterer = KMeans(n_clusters=15)\n",
    "kmeans_clusters = kmeans_clusterer.fit(hundred_dim_wordvecs)\n",
    "\n",
    "kmeans_colors = [get_color(n_clust) for n_clust in kmeans_clusters.labels_]\n",
    "\n",
    "print \"Clusters found with K-MEANS:\", len(set(kmeans_clusters.labels_))\n",
    "print [label for label in set(kmeans_clusters.labels_)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-MEANS PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmeans_data = scatter_plot(two_dim_wordvecs, word_labels, kmeans_colors)\n",
    "py.iplot(kmeans_data, filename='Word Vectors - Scatter plot K-MEANS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MANUALLY CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters found manually: 17\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, -1]\n"
     ]
    }
   ],
   "source": [
    "clusterized_map_path = path + \"sequencesMapUrl-manually-clusterized.txt\"\n",
    "seq_tuple_list = get_sequence_tuple_list(clusterized_map_path)\n",
    "\n",
    "# dict{url_code: cluster_membership} - manually clusterized\n",
    "real_cluster_membership = {tup[1].strip(): int(tup[2].strip()) for tup in seq_tuple_list}\n",
    "\n",
    "# dict{longurl: cluster_membership} - manually clusterized - never used\n",
    "real_cluster_longurl_membership = {tup[0].strip(): int(tup[2].strip()) for tup in seq_tuple_list}\n",
    "\n",
    "real_cluster_colors = [get_color(real_cluster_membership[key]) for key in seq_map]\n",
    "\n",
    "print \"Clusters found manually:\", len(set(real_cluster_membership.values()))\n",
    "print [label for label in set(real_cluster_membership.values())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MANUALLY CLUSTERING - PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "real_cluster_data = scatter_plot(two_dim_wordvecs, word_labels, real_cluster_colors)\n",
    "py.iplot(real_cluster_data, filename='Word Vectors - Scatter plot MANUALLY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.00962826550891\n",
      "recall:     0.0286343612335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/anaconda3/envs/python2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1203: DeprecationWarning:\n",
      "\n",
      "The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "\n",
      "/home/chris/anaconda3/envs/python2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "/home/chris/anaconda3/envs/python2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1304: DeprecationWarning:\n",
      "\n",
      "The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using seq_map to keep the same order, dunno if it's right\n",
    "real_membership_list = [real_cluster_membership[key] for key in seq_map]\n",
    "    \n",
    "real_membership_list = np.array(real_membership_list, dtype=\"int32\")\n",
    "\n",
    "print \"precision: \", sklearn.metrics.precision_score(real_membership_list, kmeans_clusters.labels_)\n",
    "print \"recall:    \", sklearn.metrics.recall_score(real_membership_list, kmeans_clusters.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, -1]) set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14])\n",
      "[[ 13   0   3   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  4   0   6   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  1   0  12   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 22   0   0   0  75   0   0   0   0   0   0  25   1   0   0]\n",
      " [  1   0   0   0   0   0   0  19   0   0   0   0   0   0   9]\n",
      " [  1   0   0   0   0   0   0   0   0   0   0   0  10   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  64   0   0   0   0   0]\n",
      " [  0   6   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 17   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 56   0   1   0   2   0  51   0   0   1   0  32   0   1   0]\n",
      " [  0  47   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  5   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [224   0   0   0   0   0   5   0   0   0  27   4   0  12   0]\n",
      " [  8   0   0  52   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  2   0   1   0   0   0   0   0  47   0   0   0   0   0   0]\n",
      " [  0   0   0   2   0   0  11   0   0   0   0   0   0   0   0]\n",
      " [ 17   0   3   0   1   1   1   1   0   1   0   0   3   0   0]]\n"
     ]
    }
   ],
   "source": [
    "def get_confusion_table(real_membership_list, clusters_found_labels):\n",
    "    # matrix(num_of real_clusters x clusters_found)\n",
    "    conf_table = np.zeros((len(set(real_membership_list)), len(set(clusters_found_labels))), dtype=\"int32\")\n",
    "    \n",
    "    real_clusters_set = set(real_membership_list)\n",
    "    \n",
    "    for current_clust in real_clusters_set:\n",
    "        for i in range(len(clusters_found_labels)):\n",
    "            if real_membership_list[i] == current_clust:\n",
    "                cluster_found = clusters_found_labels[i]\n",
    "                conf_table[current_clust][cluster_found] = conf_table[current_clust][cluster_found] + 1\n",
    "    return conf_table\n",
    "\n",
    "C = kmeans_clusterer.labels_\n",
    "\n",
    "confusion_table = get_confusion_table(real_membership_list, C)\n",
    "\n",
    "print set(real_membership_list), set(C)\n",
    "print confusion_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
