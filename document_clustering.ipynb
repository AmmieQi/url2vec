{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from url_sequences.sequence_manager import *\n",
    "from url_sequences.sequence_plotter import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = os.getcwd() + \"/dataset/new/cs.illinois.eduNoConstraint.words1000.depth.10/\"\n",
    "filepath= path + \"vertex.txt\"\n",
    "mappath = path + \"urlsMap.txt\"\n",
    "\n",
    "content_map = get_content_map(filepath)\n",
    "url_map = get_urlmap(mappath)\n",
    "\n",
    "# to dowload english stopwords\n",
    "# nltk.download()\n",
    "# english stopwords\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "# english stemmer\n",
    "# stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# map -> {code: token_list}\n",
    "tokens_map = to_tokens_map(content_map)\n",
    "# map -> {code: stem_list}\n",
    "stems_map = to_stems_map(content_map)\n",
    "\n",
    "# total vocabulary, list of tokens\n",
    "totalvocab_stemmed = get_total_vocab(stems_map)\n",
    "# total vocabulary, list of stems\n",
    "totalvocab_tokenized = get_total_vocab(tokens_map)\n",
    "\n",
    "# document list\n",
    "documents = [content_map[key] for key in content_map]\n",
    "codes = [key for key in content_map]\n",
    "longurls = [url_map[key] for key in content_map]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>depart</th>\n",
       "      <td>department</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comput</th>\n",
       "      <td>computer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scienc</th>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>at</th>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             words\n",
       "depart  department\n",
       "of              of\n",
       "comput    computer\n",
       "scienc     science\n",
       "at              at"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_frame = pd.DataFrame({'words': totalvocab_tokenized}, index = totalvocab_stemmed)\n",
    "vocab_frame[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terms Documents Matrix\n",
    "![Alt text](http://www.jiem.org/index.php/jiem/article/viewFile/293/252/2402 \"Very nice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((728, 156), 728)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "max_df: \n",
    "    this is the maximum frequency within the documents a given feature\n",
    "    can have to be used in the tfi-idf matrix.\n",
    "min_idf:\n",
    "    this could be an integer (e.g. 0.2) and the term would have to be in\n",
    "    at least 20% of the documents to be considered.\n",
    "ngram_range:\n",
    "    (e.g. 1,3) this just means I'll look at unigrams, bigrams and trigrams. \n",
    "\"\"\"\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_df = 0.8,\n",
    "    max_features = 200000,\n",
    "    min_df = 0.2,\n",
    "    stop_words = 'english',\n",
    "    use_idf = True,\n",
    "    tokenizer = tokenize_and_stem,\n",
    "    ngram_range = (1,3)\n",
    ")\n",
    "\n",
    "#fit the vectorizer to synopse\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents) \n",
    "print(tfidf_matrix.shape, len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# terms without stopwords or duplicates\n",
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# can be used to generate a measure of similarity between each document and the other documents in the corpus\n",
    "dist = 1 - cosine_similarity(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(n_clusters=15)\n",
    "km.fit(tfidf_matrix)\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>document</th>\n",
       "      <th>code</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>john deere scholarship in computer science dep...</td>\n",
       "      <td>344</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>jump trading scholars department of computer s...</td>\n",
       "      <td>345</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>rockwell collins scholarship department of com...</td>\n",
       "      <td>346</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>spot trading scholarship department of compute...</td>\n",
       "      <td>347</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>illinois cyber security scholars program icssp...</td>\n",
       "      <td>340</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>senior honorary department of computer science...</td>\n",
       "      <td>341</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>cisco systems wcs undergraduate scholarship de...</td>\n",
       "      <td>342</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>crowe horwath llp outstanding computer science...</td>\n",
       "      <td>343</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>state farm computer science scholarship depart...</td>\n",
       "      <td>348</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>afcea cyber studies scholarship department of ...</td>\n",
       "      <td>349</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank                                           document code  cluster\n",
       "0     0  john deere scholarship in computer science dep...  344        0\n",
       "0     1  jump trading scholars department of computer s...  345        0\n",
       "0     2  rockwell collins scholarship department of com...  346        0\n",
       "0     3  spot trading scholarship department of compute...  347        0\n",
       "0     4  illinois cyber security scholars program icssp...  340        0\n",
       "0     5  senior honorary department of computer science...  341        0\n",
       "0     6  cisco systems wcs undergraduate scholarship de...  342        0\n",
       "0     7  crowe horwath llp outstanding computer science...  343        0\n",
       "0     8  state farm computer science scholarship depart...  348        0\n",
       "0     9  afcea cyber studies scholarship department of ...  349        0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = { 'code': codes, 'rank': range(len(documents)), 'document': documents, 'cluster': clusters }\n",
    "frame = pd.DataFrame(docs, index = [clusters] , columns = ['rank', 'document', 'code', 'cluster'])\n",
    "\n",
    "frame[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 words: undergraduate, programs, students, academic, awards, graduate,\n",
      "Cluster 1 words: high, s, information, nation, programs, advancing,\n",
      "Cluster 2 words: offices, research, news, news, related, receives,\n",
      "Cluster 3 words: requires, d, ms, graduate, graduate, programs,\n",
      "Cluster 4 words: data, information, s, using, work, said,\n",
      "Cluster 5 words: awards, receives, cs, siebel, offices, research,\n",
      "Cluster 6 words: said, s, work, projects, development, team,\n",
      "Cluster 7 words: research, news, news, offices, click, years,\n",
      "Cluster 8 words: graduate, programs, applications, ms, campus, degrees,\n",
      "Cluster 9 words: awards, professor, s, performance, moone, work,\n",
      "Cluster 10 words: siebel, siebel, center, offices, academic, undergraduate,\n",
      "Cluster 11 words: awards, s, member, siebel, siebel, cs,\n",
      "Cluster 12 words: media, moone, s, professor, director, programs,\n",
      "Cluster 13 words: applications, programs, graduate, requires, ms, degrees,\n",
      "Cluster 14 words: networks, data, information, awards, s, work,\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# sort cluster centers by proximity to centroid\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "for i in range(len(set(clusters))):\n",
    "    print(\"Cluster %d words:\" % i, end='')\n",
    "    \n",
    "    for ind in order_centroids[i, :6]: # replace 6 with n words per cluster\n",
    "        print(' %s' % vocab_frame.ix[terms[ind].split(' ')].values.tolist()[0][0].encode('utf-8', 'ignore'), end=',')\n",
    "    print() #add whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "\n",
    "mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=1)\n",
    "two_dim_vec = mds.fit_transform(dist)\n",
    "\n",
    "tfidf_matrix_dense = tfidf_matrix.todense()\n",
    "docs_vecs = np.array([tfidf_matrix_dense[i].A1 for i in range(len(tfidf_matrix_dense))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "two_dim_docs_vec = tsne.fit_transform(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusters_colors = [ get_color(i) for i in clusters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\"seamless=\"seamless\" src=\"https://plot.ly/~chrispolo/16.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "k_data = scatter_plot(two_dim_vec, word_labels=longurls, colors=clusters_colors)\n",
    "py.iplot(k_data, filename=\"K-Means mds-Doc Clustering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\"seamless=\"seamless\" src=\"https://plot.ly/~chrispolo/18.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_tfidf_data = scatter_plot(two_dim_docs_vec, word_labels=longurls, colors=clusters_colors)\n",
    "py.iplot(k_tfidf_data, filename=\"K-Means tsne-Doc Clustering\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
