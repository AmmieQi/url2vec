{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Path of real membership file: ', '/home/chris/workspace/jupyter-notebook/url2vec/util/../dataset/manual-membership/urlToMembership.txt')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from util.sequence_manager import *\n",
    "from util.sequence_plotter import *\n",
    "from util.sequence_handler import *\n",
    "from util.clustering_metrics import *\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm = RealMembership()\n",
    "rm.get_membership(\"https://cs.illinois.edu/news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Url2Vec:\n",
    "    # Real Membership default file path\n",
    "    # doesn't work on ipython because of __file__\n",
    "    # __rmfile = os.path.abspath(os.path.dirname(__file__)) + \"../dataset/manual-membership/urlToMembership.txt\"\n",
    "    # __rmfile  = \"/home/chris/workspace/jupyter-notebook/url2vec/dataset/manual-membership/urlToMembership.txt\"\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__ (self, map_file):\n",
    "        self.labels_ = None\n",
    "        self.codeurl_map = get_urlmap(map_file)\n",
    "    \n",
    "    # \n",
    "    def __get_confusion_table(self, real_membership_list, clusters_found_labels):\n",
    "        assert isinstance(real_membership_list[0], int), \"Type is not int\"\n",
    "        assert isinstance(clusters_found_labels[0], int), \"Type is not int\"\n",
    "    \n",
    "       # matrix(num_of real_clusters x clusters_found)\n",
    "        conf_table = np.zeros((len(set(real_membership_list)), len(set(clusters_found_labels))))\n",
    "        real_clusters_set = set(real_membership_list)\n",
    "\n",
    "        realLabel_index_map = {}\n",
    "        index = 0\n",
    "        for c in real_clusters_set:\n",
    "            if not c in realLabel_index_map:\n",
    "                realLabel_index_map[c] = index\n",
    "                index += 1\n",
    "        print realLabel_index_map\n",
    "\n",
    "        for current_clust in realLabel_index_map.values():\n",
    "            for i in range(len(clusters_found_labels)):\n",
    "                if realLabel_index_map[real_membership_list[i]] == current_clust:\n",
    "                    cluster_found = clusters_found_labels[i]\n",
    "                    conf_table[current_clust, cluster_found] = conf_table[current_clust, cluster_found] + 1\n",
    "        return conf_table\n",
    "    \n",
    "    \n",
    "    # trains word2vec with the given parameters and returns vectors for each page\n",
    "    def __word_embedding(self, sequences_file, vecs_length=48):\n",
    "        vocab_sequences = get_seq(sequences_file, 1)\n",
    "        train_sequences = get_seq(sequences_file, 1)\n",
    "        \n",
    "        w2v_model = Word2Vec(min_count=1, negative=5, size=vecs_length)\n",
    "        w2v_model.build_vocab(vocab_sequences)\n",
    "        w2v_model.train(train_sequences)\n",
    "        return np.array([w2v_model[code] for code in self.codeurl_map])\n",
    "        \n",
    "    \n",
    "    # returns tfidf vector for each page\n",
    "    def __tfidf(self, vertex_file, vecs_length=50, tfidf=True):\n",
    "        self.codecontent_map = get_content_map(vertex_file)\n",
    "        self.pages_content = [self.codecontent_map[code] for code in self.codeurl_map]\n",
    "        self.codes = [code for code in self.codeurl_map]\n",
    "        self.longurls = [self.codeurl_map[code] for code in self.codeurl_map]\n",
    "        \n",
    "        tfidf_vectorizer = TfidfVectorizer(\n",
    "            max_df = 0.9,\n",
    "            max_features = 200000,\n",
    "            min_df = 0.05,\n",
    "            stop_words = 'english',\n",
    "            use_idf = tfidf,\n",
    "            tokenizer = tokenize_and_stem,\n",
    "            ngram_range = (1,3)\n",
    "        )\n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(self.pages_content)\n",
    "        svd = TruncatedSVD(n_components=vecs_length, algorithm=\"arpack\", random_state=1)\n",
    "        return svd.fit_transform(tfidf_matrix)\n",
    "    \n",
    "    \n",
    "    # calls the chosen algorithm with the data builded from the input arguments\n",
    "    def train(self, algorithm=HDBSCAN(min_cluster_size=10), use_w2v=True, use_tfidf=True,\n",
    "              w2v_size=48, tfidf_size=50, sequences_file=\"\", vertex_file=\"\"):\n",
    "        \n",
    "        empty_array = np.array([ [] for i in range(len(self.codeurl_map)) ])\n",
    "        w2v_vecs    = self.__word_embedding(sequences_file, vecs_length=w2v_size) if use_w2v else empty_array\n",
    "        tfidf_vecs  = self.__tfidf(vertex_file, vecs_length=tfidf_size) if use_tfidf else empty_array\n",
    "        \n",
    "        data = [ np.append(w2v_vecs[i], tfidf_vecs[i]) for i in range(len(self.codeurl_map)) ]\n",
    "        self.labels_ = algorithm.fit_predict(data)\n",
    "        self.labels_ = map(int, self.labels_)\n",
    "        return self.labels_\n",
    "            \n",
    "    \n",
    "    # needs the real membership file and the membership returned by the algorithm (already given if train was successful)\n",
    "    # returns the confusion matrix\n",
    "    def test(self, realmembership_file, alg_membership=None):\n",
    "        assert (alg_membership is not None or self.labels_ is not None), \"No train, No test !\"\n",
    "        alg_membership = self.labels_ if alg_membership is None else alg_membership\n",
    "        rm = RealMembership(fpath=realmembership_file)\n",
    "        real_membership = [int(rm.get_membership(self.codeurl_map[code])) for code in self.codeurl_map]\n",
    "        \n",
    "        return self.__get_confusion_table(real_membership, alg_membership)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nocostraint_path = os.getcwd() + \"/dataset/new/cs.illinois.edu.ListConstraint.words1000.depth10/\"\n",
    "rmfile  = \"/home/chris/workspace/jupyter-notebook/url2vec/dataset/manual-membership/urlToMembership.txt\"\n",
    "vertex_path      = nocostraint_path + \"vertex.txt\"\n",
    "map_path         = nocostraint_path + \"urlsMap.txt\"\n",
    "sequences        = nocostraint_path + \"sequenceIDs.txt\"\n",
    "\n",
    "u2v  = Url2Vec(map_path)\n",
    "u2v2 = Url2Vec(map_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vec = u2v._Url2Vec__tfidf()\n",
    "# vec2 = u2v.word_embedding(sequences)\n",
    "\n",
    "k_memb = u2v.train(algorithm=KMeans(n_clusters=15), sequences_file=sequences, vertex_file=vertex_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hd_memb = u2v2.train(sequences_file=sequences, vertex_file=vertex_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 6: 5, 8: 6, 10: 7, 12: 8, 13: 9, 14: 10, 15: 11, -1: 12}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2    3   4   5   6   7   8   9   10  11  12   13  14\n",
       "0    0   0   0    0   0   0   0   0   0   0  18   0   0    0   0\n",
       "1    0   0   0    0   0   0   0   0   0   0   9   0   0    0   0\n",
       "2    0   0  76    0   0   0  92   0   0   1   0   0   0    0   0\n",
       "3    0   0   0    0   0   0   0  28   0   0   0   0   0    0   1\n",
       "4    0   0   0    0   0   0   0   0   0   0   0   0   0    0  10\n",
       "5    0   0   0    0   0   0   0   0   0   0   0   0   6    0   0\n",
       "6    0  39   1  143   0   0   0   0   0  24   0  40  44    0   0\n",
       "7   65   0   2    0   0   0   0   0   0   0   0   0   0  249   0\n",
       "8    0   0   0    1   0   0   0   0   0   7   0   1   0    1   0\n",
       "9    0   0   0    0  57   0   0   0   0   0   0   0   0    0   0\n",
       "10   0   0   0    0   0  46   0   0   0   0   0   0   0    0   0\n",
       "11   0   0   0    0   0   0   0   0   0   0   0  11   0    0   0\n",
       "12   0   0  22    1   2   1   0   0   2   0  14   0   2    3   3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_table = u2v.test(rmfile)\n",
    "pd.DataFrame(confusion_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 6: 5, 8: 6, 10: 7, 12: 8, 13: 9, 14: 10, 15: 11, -1: 12}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>268</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>304</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1    2   3   4\n",
       "0    0   0   16   0   2\n",
       "1    0   0    8   0   1\n",
       "2    0   0  169   0   0\n",
       "3    0   0    0  28   1\n",
       "4    0   0    5   0   5\n",
       "5    0   0    0   0   6\n",
       "6    0   0  268   0  23\n",
       "7    0   0  304   0  12\n",
       "8    0   0   10   0   0\n",
       "9   56   0    0   0   1\n",
       "10   0  45    0   0   1\n",
       "11   0   0    1   0  10\n",
       "12   0   0   21   0  29"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_table_hdbscan = u2v2.test(rmfile)\n",
    "pd.DataFrame(confusion_table_hdbscan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "# k_memb  \n",
    "labels_pred_k = map(int, k_memb)\n",
    "labels_pred_h = hd_memb\n",
    "codeurl_map = get_urlmap(map_path)\n",
    "rm = RealMembership(rmfile)\n",
    "labels_true = [int(rm.get_membership(codeurl_map[code])) for code in codeurl_map]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.868063760467\n",
      "Completeness: 0.67344191781\n",
      "V Measure Score: 0.758466909163\n",
      "adjusted rand score 0.594651824083\n"
     ]
    }
   ],
   "source": [
    "print \"Homogeneity:\", metrics.homogeneity_score(labels_true, labels_pred_k)\n",
    "print \"Completeness:\", metrics.completeness_score(labels_true, labels_pred_k)\n",
    "# The V-measure is actually equivalent to the mutual information (NMI) discussed above \n",
    "# normalized by the sum of the label entropies\n",
    "print \"V Measure Score:\", metrics.v_measure_score(labels_true, labels_pred_k)\n",
    "print \"adjusted rand score:\", metrics.adjusted_rand_score(labels_true, labels_pred_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.327446197523\n",
      "Completeness: 0.756385857389\n",
      "V Measure Score: 0.457036995242\n",
      "adjusted rand score 0.203357369982\n"
     ]
    }
   ],
   "source": [
    "print \"Homogeneity:\", metrics.homogeneity_score(labels_true, labels_pred_h) # best 1\n",
    "print \"Completeness:\", metrics.completeness_score(labels_true, labels_pred_h)  # best 1\n",
    "print \"V Measure Score:\", metrics.v_measure_score(labels_true, labels_pred_h) # best 1\n",
    "print \"adjusted rand score\", metrics.adjusted_rand_score(labels_true, labels_pred_h) # best 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
