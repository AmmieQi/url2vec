{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding and Document Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import plotly.plotly as py\n",
    "from sklearn import metrics\n",
    "from hdbscan import HDBSCAN\n",
    "from plotly.graph_objs import *\n",
    "from sklearn.manifold import TSNE\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from url2vec.util.plotter import *\n",
    "from url2vec.util.metrics import *\n",
    "from url2vec.util.seqmanager import *\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# available datasets\n",
    "# cs.illinois.edu    cs.stanford.edu    eecs.mit.edu    cs.princeton.edu    cs.ox.ac.uk\n",
    "site = \"cs.illinois.edu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The crawling proccess has been done in two different ways:\n",
    "\n",
    "- **No costraint**: the crawler follows a random outlink from all of the outlinks in a given page\n",
    "- **List costraint**: the crawler follows a random outlink but only from the outlinks in \"lists\"\n",
    "\n",
    "Here we're loading all the files that the crawler has generated to train word2vec model.\n",
    "\n",
    "See the [Dataset README](https://github.com/chrisPiemonte/url2vec/tree/master/dataset \"Dataset\") for further information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3951\n"
     ]
    }
   ],
   "source": [
    "\"\"\"No-Costraint\"\"\"\n",
    "nocostraint_path   = os.getcwd() + \"/../dataset/\" + site + \"/no_constraint/words1000_depth10/\"\n",
    "vertex_nc_path     = nocostraint_path + \"vertex.txt\"\n",
    "map_nc_path        = nocostraint_path + \"urlsMap.txt\"\n",
    "\n",
    "# code -> content_string - dict \n",
    "content_nc_map = get_content_map(vertex_nc_path)\n",
    "# code -> longurl - dict \n",
    "url_nc_map = get_urlmap(map_nc_path)\n",
    "# document no-costraint list\n",
    "pages_content_nc = [content_nc_map[key] for key in content_nc_map]\n",
    "# codes no-costraint list\n",
    "codes_nc = [key for key in content_nc_map]\n",
    "# urls no-costraint list\n",
    "urls_nc = [url_nc_map[key] for key in content_nc_map]\n",
    "print(len(url_nc_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3279\n"
     ]
    }
   ],
   "source": [
    "\"\"\"List-Costraint\"\"\"\n",
    "listcostraint_path = os.getcwd() + \"/../dataset/\" + site + \"/list_constraint/words1000_depth10/\"\n",
    "vertex_lc_path     = listcostraint_path + \"vertex.txt\"\n",
    "map_lc_path        = listcostraint_path + \"urlsMap.txt\"\n",
    "\n",
    "# code -> content_string - dict \n",
    "content_lc_map = get_content_map(vertex_lc_path)\n",
    "# code -> longurl - dict \n",
    "url_lc_map = get_urlmap(map_lc_path)\n",
    "# document list-costraint list\n",
    "pages_content_lc = [content_lc_map[key] for key in content_lc_map]\n",
    "# codes list-costraint list\n",
    "codes_lc = [key for key in content_lc_map]\n",
    "# urls list-costraint list\n",
    "urls_lc = [url_lc_map[key] for key in content_lc_map]\n",
    "print(len(url_lc_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is defined **term frequency - inverse document frequency** (tf-idf) vectorizer parameters and then convert the documents (web pages) list into a tf-idf matrix.\n",
    "\n",
    "To get a Tf-idf matrix, first count word occurrences by document. This is transformed into a **document-term matrix** (dtm).![Alt text](http://www.codeproject.com/KB/WPF/NNMFSearchResultClusterin/table.jpg \"Very nice\")\n",
    "\n",
    "This is also just called a term frequency matrix.\n",
    "Then apply the term frequency-inverse document frequency weighting: words that occur frequently within a document but not frequently within the corpus receive a higher weighting as these words are assumed to contain more meaning in relation to the document.\n",
    "\n",
    "A couple things to note about the parameters defined below:\n",
    "\n",
    "**max_df**: this is the maximum frequency within the documents a given feature can have to be used in the tfi-idf matrix. If the term is in greater than 80% of the documents it probably cares little meanining\n",
    "\n",
    "**min_idf**: this could be an integer (e.g. 5) and the term would have to be in at least 5 of the documents to be considered. Here I pass 0.1; the term must be in at least 10% of the document.\n",
    "\n",
    "**ngram_range**: this just means I'll look at unigrams, bigrams and trigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TFIDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_df = 0.8,\n",
    "    max_features = 200000,\n",
    "    min_df = 0.1,\n",
    "    stop_words = 'english',\n",
    "    use_idf = True,\n",
    "    tokenizer = tokenize_and_stem,\n",
    "    ngram_range = (1,3)\n",
    ")\n",
    "\n",
    "\"\"\"TFIDF matrix No-Costraint\"\"\"\n",
    "tfidf_matrix_nc = tfidf_vectorizer.fit_transform(pages_content_nc)\n",
    "\n",
    "\"\"\"TFIDF matrix List-Costraint\"\"\"\n",
    "tfidf_matrix_lc = tfidf_vectorizer.fit_transform(pages_content_lc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec\n",
    "Word embedding algorithm. Word2vec is a two-layer neural net that processes text. Its input is a text corpus and its output is a set of vectors: feature vectors for words in that corpus.\n",
    "\n",
    "Here we're apply word2vec (skip-gram with negative sampling) to sequences generated by crawling the web site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"No-Costraint\"\"\"\n",
    "sequences_nc = nocostraint_path + \"sequenceIDs.txt\"\n",
    "\n",
    "# because of the damn generators\n",
    "vocab_sequences_nc = get_sequences(sequences_nc)\n",
    "train_sequences_nc = get_sequences(sequences_nc)\n",
    "\n",
    "w2v_model_nc = Word2Vec(min_count=1, negative=5, size=48)\n",
    "w2v_model_nc.build_vocab(vocab_sequences_nc)\n",
    "w2v_model_nc.train(train_sequences_nc)\n",
    "\n",
    "deadlinks = list(set(content_nc_map) - set(w2v_model_nc.vocab))\n",
    "for k in deadlinks:\n",
    "    del content_nc_map[k]\n",
    "\n",
    "w2v_vecs_nc = np.array([w2v_model_nc[key] for key in content_nc_map])\n",
    "\n",
    "\"\"\"List-Costraint\"\"\"\n",
    "sequences_lc = listcostraint_path + \"sequenceIDs.txt\"\n",
    "\n",
    "# because of the damn generators\n",
    "vocab_sequences_lc = get_sequences(sequences_lc)\n",
    "train_sequences_lc = get_sequences(sequences_lc)\n",
    "\n",
    "w2v_model_lc = Word2Vec(min_count=1, negative=5, size=48)\n",
    "w2v_model_lc.build_vocab(vocab_sequences_lc)\n",
    "w2v_model_lc.train(train_sequences_lc)\n",
    "\n",
    "deadlinks = list(set(url_lc_map) - set(w2v_model_lc.vocab))\n",
    "for k in deadlinks:\n",
    "    del url_lc_map[k]\n",
    "    del content_lc_map[k]\n",
    "\n",
    "w2v_vecs_lc = np.array([w2v_model_lc[key] for key in content_lc_map])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Semantic Analysis (LSA)\n",
    "Dimensionality reduction using **truncated SVD** (aka LSA).\n",
    "This transformer performs linear dimensionality reduction by means of truncated singular value decomposition (SVD). \n",
    "\n",
    "It is very similar to PCA, but operates on sample vectors directly, instead of on a covariance matrix.\n",
    "\n",
    "In particular, truncated SVD works on term count/tf-idf matrices as returned by the vectorizers. In that context, it is known as latent semantic analysis (LSA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=50)\n",
    "\n",
    "\"\"\"No-Costraint\"\"\"\n",
    "pages_tfidf_vecs_nc = svd.fit_transform(tfidf_matrix_nc)\n",
    "\n",
    "\"\"\"List-Costraint\"\"\"\n",
    "pages_tfidf_vecs_lc = svd.fit_transform(tfidf_matrix_lc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Vectors from word2vec and tf-idf\n",
    "Appending tf-idf vector at the end of the relevant word2vec vector for each page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"No-Costraint\"\"\"\n",
    "combined_vecs_nc = [np.append(pages_tfidf_vecs_nc[i], w2v_vecs_nc[i]) for i in range(len(w2v_vecs_nc))]\n",
    "\n",
    "\"\"\"List-Costraint\"\"\"\n",
    "combined_vecs_lc = [np.append(pages_tfidf_vecs_lc[i], w2v_vecs_lc[i]) for i in range(len(w2v_vecs_lc))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-SNE\n",
    "Applying t-SNE for dimensionality reduction. We need two dimensional vectors for visualization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state=1)\n",
    "\n",
    "\"\"\"No-Costraint\"\"\"\n",
    "twodim_nc = tsne.fit_transform(combined_vecs_nc)\n",
    "\n",
    "\"\"\"List-Costraint\"\"\"\n",
    "twodim_lc = tsne.fit_transform(combined_vecs_lc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Clustering\n",
    "\n",
    "K-means initializes with a pre-determined number of clusters. Each observation is assigned to a cluster (cluster assignment) so as to minimize the within cluster sum of squares. Next, the mean of the clustered observations is calculated and used as the new cluster centroid. Then, observations are reassigned to clusters and centroids recalculated in an iterative process until the algorithm reaches convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=15)\n",
    "\n",
    "\"\"\"No-Costraint\"\"\"\n",
    "kmeans.fit(combined_vecs_nc)\n",
    "kmeans_labels_nc = kmeans.labels_\n",
    "kmeans_colors_nc = [get_color(i) for i in kmeans_labels_nc]\n",
    "\n",
    "\"\"\"List-Costraint\"\"\"\n",
    "#kmeans.fit(tfidf_matrix_lc)\n",
    "kmeans.fit(combined_vecs_lc)\n",
    "kmeans_labels_lc = kmeans.labels_\n",
    "kmeans_colors_lc = [get_color(i) for i in kmeans_labels_lc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Means no-costraint plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kmeans_data_nc = scatter_plot(twodim_nc, word_labels=urls_nc, colors=kmeans_colors_nc)\n",
    "py.iplot(kmeans_data_nc, filename=\"K-Means TFIDF-W2V Clustering - No-Costraint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <a href=\"https://plot.ly/~chrispolo/42\" \n",
    "        target=\"_blank\" title=\"y\" \n",
    "        style=\"display: block; text-align: center;\">\n",
    "            <img src=\"../dataset/img/nc_ed_wordvectors_scatter_plot_KMEANS.png\" \n",
    "                alt=\"y\" style=\"max-width: 100%;width: 1121px;\"  \n",
    "                width=\"100%\" onerror=\"this.onerror=null;this.src='https://plot.ly/404';\" />\n",
    "    </a>\n",
    "    <script data-plotly=\"chrispolo:42\"  src=\"https://plot.ly/embed.js\" async></script>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Means list-costraint plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kmeans_data_lc = scatter_plot(twodim_lc, word_labels=urls_lc, colors=kmeans_colors_lc)\n",
    "py.iplot(kmeans_data_lc, filename=\"K-Means TFIDF-W2V Clustering - List-Costraint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <a href=\"https://plot.ly/~chrispolo/36\" \n",
    "        target=\"_blank\" title=\"y\" \n",
    "        style=\"display: block; text-align: center;\">\n",
    "            <img src=\"../dataset/img/lc_ed_wordvectors_scatter_plot_KMEANS.png\" \n",
    "                alt=\"y\" style=\"max-width: 100%;width: 1121px;\"  \n",
    "                width=\"100%\" onerror=\"this.onerror=null;this.src='https://plot.ly/404';\" />\n",
    "    </a>\n",
    "    <script data-plotly=\"chrispolo:36\"  src=\"https://plot.ly/embed.js\" async></script>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDBSCAN Clsustering\n",
    "\n",
    "Hierarchical Density-Based Spatial Clustering of Applications with Noise. Performs DBSCAN over varying epsilon values and integrates the result to find a clustering that gives the best stability over epsilon. This allows HDBSCAN to find clusters of varying densities (unlike DBSCAN), and be more robust to parameter selection.\n",
    "\n",
    "**params**:\n",
    "\n",
    "- **min_cluster_size** : minimum nodes to form a cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters found with HDBSCAN on No-costraint Dataset: 32\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, -1] \n",
      "\n",
      "Clusters found with HDBSCAN on List-costraint Dataset: 25\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, -1]\n"
     ]
    }
   ],
   "source": [
    "hdbscan = HDBSCAN(min_cluster_size=10)\n",
    "\n",
    "\"\"\"No-Costraint\"\"\"\n",
    "hdbscan_labels_nc = hdbscan.fit_predict(combined_vecs_nc)\n",
    "hdbscan_colors_nc = [get_color(n_clust) for n_clust in hdbscan_labels_nc]\n",
    "\n",
    "print \"Clusters found with HDBSCAN on No-costraint Dataset:\", len(set(hdbscan_labels_nc))\n",
    "print [label for label in set(hdbscan_labels_nc)], \"\\n\"\n",
    "\n",
    "\"\"\"List-Costraint\"\"\"\n",
    "hdbscan_labels_lc = hdbscan.fit_predict(combined_vecs_lc)\n",
    "hdbscan_colors_lc = [get_color(n_clust) for n_clust in hdbscan_labels_lc]\n",
    "\n",
    "print \"Clusters found with HDBSCAN on List-costraint Dataset:\", len(set(hdbscan_labels_lc))\n",
    "print [label for label in set(hdbscan_labels_lc)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HDBSCAN no-costraint plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hdbscan_data_nc = scatter_plot(twodim_nc, word_labels=urls_nc, colors=hdbscan_colors_nc)\n",
    "py.iplot(hdbscan_data_nc, filename=\"HDBSCAN TFIDF-W2V Clustering - No-Costraint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <a href=\"https://plot.ly/~chrispolo/38\" \n",
    "        target=\"_blank\" title=\"y\" \n",
    "        style=\"display: block; text-align: center;\">\n",
    "            <img src=\"../dataset/img/nc_ed_wordvectors_scatter_plot_HDBSCAN.png\" \n",
    "                alt=\"y\" style=\"max-width: 100%;width: 1121px;\"  \n",
    "                width=\"100%\" onerror=\"this.onerror=null;this.src='https://plot.ly/404';\" />\n",
    "    </a>\n",
    "    <script data-plotly=\"chrispolo:38\"  src=\"https://plot.ly/embed.js\" async></script>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HDBSCAN list-costraint plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hdbscan_data_lc = scatter_plot(twodim_lc, word_labels=urls_lc, colors=hdbscan_colors_lc)\n",
    "py.iplot(hdbscan_data_lc, filename=\"HDBSCAN TFIDF-W2V Clustering - List-Costraint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <a href=\"https://plot.ly/~chrispolo/40\" \n",
    "        target=\"_blank\" title=\"y\" \n",
    "        style=\"display: block; text-align: center;\">\n",
    "            <img src=\"../dataset/img/lc_ed_wordvectors_scatter_plot_HDBSCAN.png\" \n",
    "                alt=\"y\" style=\"max-width: 100%;width: 1121px;\"  \n",
    "                width=\"100%\" onerror=\"this.onerror=null;this.src='https://plot.ly/404';\" />\n",
    "    </a>\n",
    "    <script data-plotly=\"chrispolo:40\"  src=\"https://plot.ly/embed.js\" async></script>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Evaluating the performance of a clustering algorithm is not as trivial as counting the number of errors or the precision and recall of a supervised classification algorithm. In particular any evaluation metric should not take the absolute values of the cluster labels into account but rather if this clustering define separations of the data similar to some ground truth set of classes or satisfying some assumption such that members belong to the same class are more similar that members of different classes according to some similarity metric.\n",
    "\n",
    "See the [scikit-learn documentaion](http://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation \"ti\") for futher information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics:\n",
    "\n",
    "- **Homogeneity**: each cluster contains only members of a single class\n",
    "\n",
    "\n",
    "- **Completeness**: all members of a given class are assigned to the same cluster\n",
    "\n",
    "\n",
    "- **Adjusted Rand index**: Given the knowledge of the *ground truth* class assignments and our clustering algorithm assignments of the same samples, the adjusted Rand index is a function that measures the similarity of the two assignments, ignoring permutations and with chance normalization\n",
    "\n",
    "\n",
    "- **V-measure**: The V-measure is actually equivalent to the mutual information (NMI) discussed above normalized by the sum of the label entropies\n",
    "\n",
    "\n",
    "- **Mutual Information based scores**: Given the knowledge of the ground truth class assignments and our clustering algorithm assignments of the same samples, the Mutual Information is a function that measures the agreement of the two assignments, ignoring permutations. Two different normalized versions of this measure are available, Normalized Mutual Information(NMI) and Adjusted Mutual Information(AMI). NMI is often used in the literature while AMI was proposed more recently and is normalized against chance\n",
    "\n",
    "\n",
    "- **Silhouette**: If the ground truth labels are not known, evaluation must be performed using the model itself. The Silhouette Coefficient is an example of such an evaluation, where a higher Silhouette Coefficient score relates to a model with better defined clusters. The score is bounded between -1 for incorrect clustering and +1 for highly dense clustering. Scores around zero indicate overlapping clusters. The score is higher when clusters are dense and well separated, which relates to a standard concept of a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Url not found\n",
      "Url not found\n",
      "Url not found\n",
      "Url not found\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83</td>\n",
       "      <td>55</td>\n",
       "      <td>112</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>27</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1    2   3   4   5    6    7   8   9  ...   15   16  17   18  19  20  \\\n",
       "0   83  55  112  16   0   0  146  239   0  37 ...    0  171   0  123   0   3   \n",
       "1    0   2    1   7   0   0    0    1   0   0 ...    0    1   0    0   0   0   \n",
       "2    0   1    2   2   1   0    1    3   0   0 ...    1    3   0    2   0   0   \n",
       "3    0   0    0   0   0   0    0    0  11   0 ...    0    0   2    0   0   0   \n",
       "4    0   0    0   0   0   0    0    0   0   0 ...    0    0   7    0   0   0   \n",
       "5    2  13    1   0   0   0   11   23   0   0 ...    0    2   1    9   0   0   \n",
       "6    1   0    6   0   0   0    6    9   9   0 ...    0    4   1   16   0   0   \n",
       "7    0   2    0   0   0   0    3    0  23   0 ...    0    0   1    1   0   0   \n",
       "8    3   3    4   3   0   0    5    6   2   5 ...    3    6   0    6   0  25   \n",
       "9    7   2    8  26   0   0   14   22   0   2 ...    0    8   0   14   2   2   \n",
       "10   9   5   18  26   0   0   21   31   0  24 ...    0   21   0   10   0   1   \n",
       "11   0   0    0   0   0   0    0    0   0  40 ...    0    0   0    0   0   2   \n",
       "12   0   3    1   5   0   0    2    2   0   0 ...    0    0   0    1   0   0   \n",
       "13   4   1    3   2   0   0    6   13   1   0 ...    3   16   0   24   0   0   \n",
       "14   0   0    0   0   0  10    0    0   0   0 ...    0    0   0    0   0   0   \n",
       "15   0   0    0   0   0   1    0    0   0   0 ...    0    0   0    0   0   0   \n",
       "16   0   0    0   2   0  42    1    0   0   0 ...    0    0   0    0   0   0   \n",
       "17   0   1    3   0   1   0    3   12   0   0 ...    0    4   0   11  52   0   \n",
       "18   0   0    2   0  19   0    1    3   0   0 ...    1    0   0    1  10   0   \n",
       "19   5   0    6   0   1   0    1    2   0   0 ...    0    0   0    7   3   0   \n",
       "20   0   0    2  12   0   0    6    9   1  16 ...    5    3   0    2   0   3   \n",
       "21   6   6   16   3   5  13   27   48   2   0 ...   10   13   6   20   1   6   \n",
       "\n",
       "    21   22  23   24  \n",
       "0    0  170   0    0  \n",
       "1    3    1   0    1  \n",
       "2   29    0   0    0  \n",
       "3    0    0   0    0  \n",
       "4    0    0   0    0  \n",
       "5    0   16   0    0  \n",
       "6    0    6   0    0  \n",
       "7    0    0   0    0  \n",
       "8    0    3   0    0  \n",
       "9    0   14   1  266  \n",
       "10   0   16   0    0  \n",
       "11   0    0   0    1  \n",
       "12   0    0   0    0  \n",
       "13   0   16  39    0  \n",
       "14   0    0   0    0  \n",
       "15   0    0   0    0  \n",
       "16   0    0   0    0  \n",
       "17   0    5   0    0  \n",
       "18   0    2   0    0  \n",
       "19   0    6   0    0  \n",
       "20   1    3   1    2  \n",
       "21   2   30   6    0  \n",
       "\n",
       "[22 rows x 25 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt = GroundTruth(os.getcwd() + \"/../dataset/\" + site + \"/ground_truth/urlToMembership.txt\")\n",
    "\n",
    "ground_truth_nc = [int(gt.get_groundtruth(url_nc_map[key])) for key in content_nc_map]\n",
    "ground_truth_lc = [int(gt.get_groundtruth(url_lc_map[key])) for key in content_lc_map]\n",
    "\n",
    "pd.DataFrame(get_confusion_table(ground_truth_lc, [int(x) for x in kmeans_labels_lc]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Homogeneity</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>V-Measure Score</th>\n",
       "      <th>Adjusted Rand index</th>\n",
       "      <th>Mutual Information</th>\n",
       "      <th>Silhouette</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NoCostraint - HDBSCAN</th>\n",
       "      <td>0.134335</td>\n",
       "      <td>0.176214</td>\n",
       "      <td>0.152451</td>\n",
       "      <td>-0.035699</td>\n",
       "      <td>0.101228</td>\n",
       "      <td>-0.082619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoCostraint - K-MEANS</th>\n",
       "      <td>0.368164</td>\n",
       "      <td>0.305244</td>\n",
       "      <td>0.333764</td>\n",
       "      <td>0.133715</td>\n",
       "      <td>0.284614</td>\n",
       "      <td>0.132209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ListCostraint - HDBSCAN</th>\n",
       "      <td>0.153679</td>\n",
       "      <td>0.174101</td>\n",
       "      <td>0.163254</td>\n",
       "      <td>-0.038376</td>\n",
       "      <td>0.124850</td>\n",
       "      <td>-0.031929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ListCostraint - K-MEANS</th>\n",
       "      <td>0.386946</td>\n",
       "      <td>0.283635</td>\n",
       "      <td>0.327332</td>\n",
       "      <td>0.127700</td>\n",
       "      <td>0.263863</td>\n",
       "      <td>0.138663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Homogeneity  Completeness  V-Measure Score  \\\n",
       "NoCostraint - HDBSCAN       0.134335      0.176214         0.152451   \n",
       "NoCostraint - K-MEANS       0.368164      0.305244         0.333764   \n",
       "ListCostraint - HDBSCAN     0.153679      0.174101         0.163254   \n",
       "ListCostraint - K-MEANS     0.386946      0.283635         0.327332   \n",
       "\n",
       "                         Adjusted Rand index  Mutual Information  Silhouette  \n",
       "NoCostraint - HDBSCAN              -0.035699            0.101228   -0.082619  \n",
       "NoCostraint - K-MEANS               0.133715            0.284614    0.132209  \n",
       "ListCostraint - HDBSCAN            -0.038376            0.124850   -0.031929  \n",
       "ListCostraint - K-MEANS             0.127700            0.263863    0.138663  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame([\n",
    "        [\n",
    "            # hdbscan nocostraint\n",
    "            metrics.homogeneity_score(ground_truth_nc, hdbscan_labels_nc),\n",
    "            metrics.completeness_score(ground_truth_nc, hdbscan_labels_nc),\n",
    "            metrics.v_measure_score(ground_truth_nc, hdbscan_labels_nc),\n",
    "            metrics.adjusted_rand_score(ground_truth_nc, hdbscan_labels_nc),\n",
    "            metrics.adjusted_mutual_info_score(ground_truth_nc, hdbscan_labels_nc),\n",
    "            metrics.silhouette_score(np.array(combined_vecs_nc), hdbscan_labels_nc, metric='euclidean')\n",
    "        ],\n",
    "        [\n",
    "            # kmeans nocostraint\n",
    "            metrics.homogeneity_score(ground_truth_nc, kmeans_labels_nc),\n",
    "            metrics.completeness_score(ground_truth_nc, kmeans_labels_nc),\n",
    "            metrics.v_measure_score(ground_truth_nc, kmeans_labels_nc),\n",
    "            metrics.adjusted_rand_score(ground_truth_nc, kmeans_labels_nc),\n",
    "            metrics.adjusted_mutual_info_score(ground_truth_nc, kmeans_labels_nc),\n",
    "            metrics.silhouette_score(np.array(combined_vecs_nc), kmeans_labels_nc, metric='euclidean')\n",
    "        ],\n",
    "        [\n",
    "            # hdbscan listcostraint\n",
    "            metrics.homogeneity_score(ground_truth_lc, hdbscan_labels_lc),\n",
    "            metrics.completeness_score(ground_truth_lc, hdbscan_labels_lc),\n",
    "            metrics.v_measure_score(ground_truth_lc, hdbscan_labels_lc),\n",
    "            metrics.adjusted_rand_score(ground_truth_lc, hdbscan_labels_lc),\n",
    "            metrics.adjusted_mutual_info_score(ground_truth_lc, hdbscan_labels_lc),\n",
    "            metrics.silhouette_score(np.array(combined_vecs_lc), hdbscan_labels_lc, metric='euclidean')\n",
    "        ],\n",
    "        [\n",
    "            # kmeans listcostraint\n",
    "            metrics.homogeneity_score(ground_truth_lc, kmeans_labels_lc),\n",
    "            metrics.completeness_score(ground_truth_lc, kmeans_labels_lc),\n",
    "            metrics.v_measure_score(ground_truth_lc, kmeans_labels_lc),\n",
    "            metrics.adjusted_rand_score(ground_truth_lc, kmeans_labels_lc),\n",
    "            metrics.adjusted_mutual_info_score(ground_truth_lc, kmeans_labels_lc),\n",
    "            metrics.silhouette_score(np.array(combined_vecs_lc), kmeans_labels_lc, metric='euclidean')\n",
    "        ]],\n",
    "        index=[ \n",
    "            \"NoCostraint - HDBSCAN\", \n",
    "            \"NoCostraint - K-MEANS\",  \n",
    "            \"ListCostraint - HDBSCAN\", \n",
    "            \"ListCostraint - K-MEANS\"\n",
    "        ],\n",
    "        columns=[\n",
    "            \"Homogeneity\", \n",
    "            \"Completeness\", \n",
    "            \"V-Measure Score\", \n",
    "            \"Adjusted Rand index\", \n",
    "            \"Mutual Information\",\n",
    "            \"Silhouette\"\n",
    "        ])\n",
    "\n",
    "metrics_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
