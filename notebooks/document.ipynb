{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "from url2vec.util.plotter import *\n",
    "from url2vec.util.seqmanager import *\n",
    "\n",
    "from sklearn import metrics\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from __future__ import print_function\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cs.illinois.edu    cs.stanford.edu    eecs.mit.edu\n",
    "site = \"cs.stanford.edu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is defined **term frequency - inverse document frequency** (tf-idf) vectorizer parameters and then convert the documents (web pages) list into a tf-idf matrix.\n",
    "\n",
    "To get a Tf-idf matrix, first count word occurrences by document. This is transformed into a **document-term matrix** (dtm).![Alt text](http://www.codeproject.com/KB/WPF/NNMFSearchResultClusterin/table.jpg \"Very nice\")\n",
    "\n",
    "This is also just called a term frequency matrix.\n",
    "Then apply the term frequency-inverse document frequency weighting: words that occur frequently within a document but not frequently within the corpus receive a higher weighting as these words are assumed to contain more meaning in relation to the document.\n",
    "\n",
    "A couple things to note about the parameters defined below:\n",
    "\n",
    "**max_df**: this is the maximum frequency within the documents a given feature can have to be used in the tfi-idf matrix. If the term is in greater than 80% of the documents it probably cares little meanining\n",
    "\n",
    "**min_idf**: this could be an integer (e.g. 5) and the term would have to be in at least 5 of the documents to be considered. Here I pass 0.1; the term must be in at least 10% of the document.\n",
    "\n",
    "**ngram_range**: this just means I'll look at unigrams, bigrams and trigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_df = 0.8,\n",
    "    max_features = 200000,\n",
    "    min_df = 0.1,\n",
    "    stop_words = 'english',\n",
    "    use_idf = True,\n",
    "    tokenizer = tokenize_and_stem,\n",
    "    ngram_range = (1,3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The crawling proccess has been done in two different ways:\n",
    "\n",
    "- **No costraint**: the crawler follows a random outlink from all of the outlinks in a given page\n",
    "- **List costraint**: the crawler follows a random outlink but only from the outlinks in \"lists\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No-costraint documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nocostraint_path = os.getcwd() + \"/../dataset/\" + site + \"/no_constraint/words1000_depth10/\"\n",
    "vertex_nc_path   = nocostraint_path + \"vertex.txt\"\n",
    "map_nc_path      = nocostraint_path + \"urlsMap.txt\"\n",
    "\n",
    "codecontent_map_nc = get_content_map(vertex_nc_path)\n",
    "urlmap_nc          = get_urlmap(map_nc_path)\n",
    "\n",
    "documents_nc = [codecontent_map_nc[key] for key in codecontent_map_nc]\n",
    "codes_nc     = [key for key in codecontent_map_nc]\n",
    "urls_nc      = [urlmap_nc[key] for key in codecontent_map_nc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine-Similarity\n",
    "Cosine similarity is measured against the tf-idf matrix and can be used to generate a measure of similarity between each document and the other documents in the corpus.\n",
    "\n",
    "Subtracting it from 1 provides cosine distance which I will use for plotting on a euclidean (2-dimensional) plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               \n",
      "documents  1458\n",
      "terms       843\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_matrix_nc = tfidf_vectorizer.fit_transform(documents_nc)\n",
    "dist_nc = 1 - cosine_similarity(tfidf_matrix_nc)\n",
    "\n",
    "print(pd.DataFrame(\n",
    "        {\"documents\":tfidf_matrix_nc.shape[0], \"terms\":tfidf_matrix_nc.shape[1]}, \n",
    "        index=[\"\"]).T)\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering on No-costraint documents\n",
    "#### K-Means\n",
    "\n",
    "K-means initializes with a pre-determined number of clusters. Each observation is assigned to a cluster (cluster assignment) so as to minimize the within cluster sum of squares. Next, the mean of the clustered observations is calculated and used as the new cluster centroid. Then, observations are reassigned to clusters and centroids recalculated in an iterative process until the algorithm reaches convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recurrentjs sentence memorization demo deep re...</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>reinforcejs gridworld with dynamic programming...</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tsnejs demo tsnejs demo intro t sne is a visua...</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nips accepted papers nips papers in nicer form...</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>z cmpt home publications cv contact warning th...</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             document code\n",
       "2   recurrentjs sentence memorization demo deep re...  344\n",
       "6   reinforcejs gridworld with dynamic programming...  345\n",
       "10  tsnejs demo tsnejs demo intro t sne is a visua...  346\n",
       "6   nips accepted papers nips papers in nicer form...  347\n",
       "10  z cmpt home publications cv contact warning th...  340"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=15)\n",
    "kmeans_labels_nc = kmeans.fit_predict(tfidf_matrix_nc)\n",
    "\n",
    "docs_nc = { \n",
    "    'code': codes_nc,\n",
    "    'document': documents_nc\n",
    "}\n",
    "frame_nc = pd.DataFrame(docs_nc, index=[kmeans_labels_nc] , columns=['document', 'code'])\n",
    "\n",
    "frame_nc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic modeling\n",
    "Some fancy indexing and sorting on each cluster to identify which are the top n words that are nearest to the cluster centroid. This gives an idea of the main topic of each the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cluster 0 - Top Words</th>\n",
       "      <td>student</td>\n",
       "      <td>cs</td>\n",
       "      <td>programming</td>\n",
       "      <td>science</td>\n",
       "      <td>computations</td>\n",
       "      <td>degrees</td>\n",
       "      <td>ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 1 - Top Words</th>\n",
       "      <td>pm</td>\n",
       "      <td>pm</td>\n",
       "      <td>cs</td>\n",
       "      <td>student</td>\n",
       "      <td>ms</td>\n",
       "      <td>access</td>\n",
       "      <td>masters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 2 - Top Words</th>\n",
       "      <td>t</td>\n",
       "      <td>day</td>\n",
       "      <td>time</td>\n",
       "      <td>just</td>\n",
       "      <td>very</td>\n",
       "      <td>good</td>\n",
       "      <td>hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 3 - Top Words</th>\n",
       "      <td>student</td>\n",
       "      <td>cs</td>\n",
       "      <td>ms</td>\n",
       "      <td>access</td>\n",
       "      <td>masters</td>\n",
       "      <td>degrees</td>\n",
       "      <td>computations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 4 - Top Words</th>\n",
       "      <td>paper</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>publications</td>\n",
       "      <td>international</td>\n",
       "      <td>learn</td>\n",
       "      <td>project</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 5 - Top Words</th>\n",
       "      <td>t</td>\n",
       "      <td>w</td>\n",
       "      <td>m</td>\n",
       "      <td>student</td>\n",
       "      <td>cs</td>\n",
       "      <td>ms</td>\n",
       "      <td>access</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 6 - Top Words</th>\n",
       "      <td>learn</td>\n",
       "      <td>models</td>\n",
       "      <td>networks</td>\n",
       "      <td>control</td>\n",
       "      <td>machine</td>\n",
       "      <td>code</td>\n",
       "      <td>algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 7 - Top Words</th>\n",
       "      <td>webauth</td>\n",
       "      <td>page</td>\n",
       "      <td>machine</td>\n",
       "      <td>login</td>\n",
       "      <td>webauth</td>\n",
       "      <td>csid</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 8 - Top Words</th>\n",
       "      <td>cs</td>\n",
       "      <td>list</td>\n",
       "      <td>b</td>\n",
       "      <td>project</td>\n",
       "      <td>course</td>\n",
       "      <td>programming</td>\n",
       "      <td>please</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 9 - Top Words</th>\n",
       "      <td>robotics</td>\n",
       "      <td>control</td>\n",
       "      <td>human</td>\n",
       "      <td>designed</td>\n",
       "      <td>project</td>\n",
       "      <td>learn</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 10 - Top Words</th>\n",
       "      <td>data</td>\n",
       "      <td>publications</td>\n",
       "      <td>high</td>\n",
       "      <td>algorithms</td>\n",
       "      <td>group</td>\n",
       "      <td>models</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 11 - Top Words</th>\n",
       "      <td>programming</td>\n",
       "      <td>student</td>\n",
       "      <td>course</td>\n",
       "      <td>please</td>\n",
       "      <td>cs</td>\n",
       "      <td>time</td>\n",
       "      <td>applications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 12 - Top Words</th>\n",
       "      <td>designed</td>\n",
       "      <td>robotics</td>\n",
       "      <td>control</td>\n",
       "      <td>student</td>\n",
       "      <td>cs</td>\n",
       "      <td>technology</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 13 - Top Words</th>\n",
       "      <td>student</td>\n",
       "      <td>cs</td>\n",
       "      <td>pm</td>\n",
       "      <td>science</td>\n",
       "      <td>degrees</td>\n",
       "      <td>access</td>\n",
       "      <td>ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 14 - Top Words</th>\n",
       "      <td>cs</td>\n",
       "      <td>student</td>\n",
       "      <td>access</td>\n",
       "      <td>science</td>\n",
       "      <td>computations</td>\n",
       "      <td>masters</td>\n",
       "      <td>ms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  1             2             3  \\\n",
       "Cluster 0 - Top Words       student            cs   programming   \n",
       "Cluster 1 - Top Words            pm            pm            cs   \n",
       "Cluster 2 - Top Words             t           day          time   \n",
       "Cluster 3 - Top Words       student            cs            ms   \n",
       "Cluster 4 - Top Words         paper  intelligence  publications   \n",
       "Cluster 5 - Top Words             t             w             m   \n",
       "Cluster 6 - Top Words         learn        models      networks   \n",
       "Cluster 7 - Top Words       webauth          page       machine   \n",
       "Cluster 8 - Top Words            cs          list             b   \n",
       "Cluster 9 - Top Words      robotics       control         human   \n",
       "Cluster 10 - Top Words         data  publications          high   \n",
       "Cluster 11 - Top Words  programming       student        course   \n",
       "Cluster 12 - Top Words     designed      robotics       control   \n",
       "Cluster 13 - Top Words      student            cs            pm   \n",
       "Cluster 14 - Top Words           cs       student        access   \n",
       "\n",
       "                                    4             5            6             7  \n",
       "Cluster 0 - Top Words         science  computations      degrees            ms  \n",
       "Cluster 1 - Top Words         student            ms       access       masters  \n",
       "Cluster 2 - Top Words            just          very         good          hour  \n",
       "Cluster 3 - Top Words          access       masters      degrees  computations  \n",
       "Cluster 4 - Top Words   international         learn      project          code  \n",
       "Cluster 5 - Top Words         student            cs           ms        access  \n",
       "Cluster 6 - Top Words         control       machine         code    algorithms  \n",
       "Cluster 7 - Top Words           login       webauth         csid            cs  \n",
       "Cluster 8 - Top Words         project        course  programming        please  \n",
       "Cluster 9 - Top Words        designed       project        learn             m  \n",
       "Cluster 10 - Top Words     algorithms         group       models             m  \n",
       "Cluster 11 - Top Words         please            cs         time  applications  \n",
       "Cluster 12 - Top Words        student            cs   technology            pm  \n",
       "Cluster 13 - Top Words        science       degrees       access            ms  \n",
       "Cluster 14 - Top Words        science  computations      masters            ms  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map -> {code: token_list}\n",
    "tokens_nc_map = to_tokens_map(codecontent_map_nc)\n",
    "# map -> {code: stem_list}\n",
    "stems_nc_map = to_stems_map(codecontent_map_nc)\n",
    "\n",
    "# total vocabulary, list of tokens\n",
    "totalvocab_nc_stemmed = [stem for key in codecontent_map_nc for stem in stems_nc_map[key]]\n",
    "# total vocabulary, list of stems\n",
    "totalvocab_nc_tokenized = [stem for key in codecontent_map_nc for stem in tokens_nc_map[key]]\n",
    "\n",
    "vocab_nc_frame = pd.DataFrame({'words': totalvocab_nc_tokenized}, index = totalvocab_nc_stemmed)\n",
    "terms_nc = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# sort cluster centers by proximity to centroid\n",
    "order_centroids_nc = kmeans.cluster_centers_.argsort()[:,::-1]\n",
    "\n",
    "num_clusters_nc = len(set(kmeans_labels_nc))\n",
    "words_matrix_nc = [None] * num_clusters_nc\n",
    "top_n = 7\n",
    "\n",
    "for i in range(num_clusters_nc):\n",
    "    cluster_chart = [vocab_nc_frame.ix[terms_nc[ind].split(' ')].values.tolist()[0][0] \n",
    "                     for ind in order_centroids_nc[i,:top_n]]\n",
    "    words_matrix_nc[i] = cluster_chart\n",
    "    \n",
    "pd.DataFrame(\n",
    "    words_matrix_nc, \n",
    "    index = [\"Cluster \" + str(i) + \" - Top Words\" for i in range(num_clusters_nc)],\n",
    "    columns = list(range(1, top_n+1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Plot\n",
    "Applying t-SNE for dimensionality reduction. We need two dimensional vectors for visualization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\"seamless=\"seamless\" src=\"https://plot.ly/~chrispolo/70.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsne = TSNE(n_components=2, random_state=1)\n",
    "twodim_docs_nc = tsne.fit_transform(dist_nc)\n",
    "\n",
    "clusters_colors_nc = [ get_color(i) for i in kmeans_labels_nc]\n",
    "\n",
    "kmeans_data = scatter_plot(twodim_docs_nc, word_labels=urls_nc, colors=clusters_colors_nc)\n",
    "py.iplot(kmeans_data, filename=\"K-Means t-SNE nocostraint - Doc Clustering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <a href=\"https://plot.ly/~chrispolo/70\" \n",
    "        target=\"_blank\" title=\"y\" \n",
    "        style=\"display: block; text-align: center;\">\n",
    "            <img src=\"../dataset/img/nc_docs_wordvectors_scatter_plot_KMEANS.png\" \n",
    "                alt=\"y\" style=\"max-width: 100%;width: 1121px;\"  \n",
    "                width=\"100%\" onerror=\"this.onerror=null;this.src='https://plot.ly/404';\" />\n",
    "    </a>\n",
    "    <script data-plotly=\"chrispolo:70\"  src=\"https://plot.ly/embed.js\" async></script>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List-costraint documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "listcostraint_path = os.getcwd() + \"/../dataset/\" + site + \"/list_constraint/words1000_depth10/\"\n",
    "vertex_lc_path     = listcostraint_path + \"vertex.txt\"\n",
    "map_lc_path        = listcostraint_path + \"urlsMap.txt\"\n",
    "\n",
    "codecontent_map_lc = get_content_map(vertex_lc_path)\n",
    "urlmap_lc = get_urlmap(map_lc_path)\n",
    "\n",
    "# document list\n",
    "documents_lc = [codecontent_map_lc[key] for key in codecontent_map_lc]\n",
    "codes_lc     = [key for key in codecontent_map_lc]\n",
    "urls_lc      = [urlmap_lc[key] for key in codecontent_map_lc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine-Similarity\n",
    "Cosine similarity is measured against the tf-idf matrix and can be used to generate a measure of similarity between each document and the other documents in the corpus.\n",
    "\n",
    "Subtracting it from 1 provides cosine distance which I will use for plotting on a euclidean (2-dimensional) plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              \n",
      "documents  152\n",
      "terms      330\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_matrix_lc = tfidf_vectorizer.fit_transform(documents_lc)\n",
    "\n",
    "dist_lc = 1 - cosine_similarity(tfidf_matrix_lc)\n",
    "\n",
    "print(pd.DataFrame({\"documents\":tfidf_matrix_lc.shape[0], \"terms\":tfidf_matrix_lc.shape[1]}, index=[\"\"]).T)\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering on List-costraint documents\n",
    "#### K-Means\n",
    "K-means initializes with a pre-determined number of clusters. Each observation is assigned to a cluster (cluster assignment) so as to minimize the within cluster sum of squares. Next, the mean of the clustered observations is calculated and used as the new cluster centroid. Then, observations are reassigned to clusters and centroids recalculated in an iterative process until the algorithm reaches convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>skip to skip to content skip to navigation csi...</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>skip to skip to content skip to navigation csi...</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>skip to skip to content skip to navigation csi...</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>skip to skip to content skip to navigation csi...</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>skip to skip to content skip to navigation csi...</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document code\n",
       "4  skip to skip to content skip to navigation csi...  216\n",
       "1  skip to skip to content skip to navigation csi...  214\n",
       "4  skip to skip to content skip to navigation csi...  215\n",
       "9  skip to skip to content skip to navigation csi...  212\n",
       "4  skip to skip to content skip to navigation csi...  213"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=15)\n",
    "kmeans_labels_lc = kmeans.fit_predict(tfidf_matrix_lc)\n",
    "docs_lc = {\n",
    "    'code': codes_lc,\n",
    "    'document': documents_lc\n",
    "}\n",
    "\n",
    "frame_lc = pd.DataFrame(docs_lc, index = [kmeans_labels_lc] , columns = ['document', 'code'])\n",
    "frame_lc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic modeling\n",
    "Some fancy indexing and sorting on each cluster to identify which are the top n words that are nearest to the cluster centroid. This gives an idea of the main topic of each the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cluster 0 - Top Words</th>\n",
       "      <td>control</td>\n",
       "      <td>teaching</td>\n",
       "      <td>combination</td>\n",
       "      <td>links</td>\n",
       "      <td>fields</td>\n",
       "      <td>dynamical</td>\n",
       "      <td>updated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 1 - Top Words</th>\n",
       "      <td>application</td>\n",
       "      <td>deadlines</td>\n",
       "      <td>online</td>\n",
       "      <td>please</td>\n",
       "      <td>submitting</td>\n",
       "      <td>admissions</td>\n",
       "      <td>ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 2 - Top Words</th>\n",
       "      <td>list</td>\n",
       "      <td>b</td>\n",
       "      <td>project</td>\n",
       "      <td>p</td>\n",
       "      <td>practical</td>\n",
       "      <td>training</td>\n",
       "      <td>programming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 3 - Top Words</th>\n",
       "      <td>professor</td>\n",
       "      <td>professor</td>\n",
       "      <td>faculty</td>\n",
       "      <td>secure</td>\n",
       "      <td>humanities</td>\n",
       "      <td>focusing</td>\n",
       "      <td>computer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 4 - Top Words</th>\n",
       "      <td>admissions</td>\n",
       "      <td>skip</td>\n",
       "      <td>computer</td>\n",
       "      <td>search</td>\n",
       "      <td>campus</td>\n",
       "      <td>gates</td>\n",
       "      <td>building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 5 - Top Words</th>\n",
       "      <td>motions</td>\n",
       "      <td>learn</td>\n",
       "      <td>robotics</td>\n",
       "      <td>dynamical</td>\n",
       "      <td>demonstrated</td>\n",
       "      <td>modeling</td>\n",
       "      <td>based</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 6 - Top Words</th>\n",
       "      <td>robotics</td>\n",
       "      <td>design</td>\n",
       "      <td>humanities</td>\n",
       "      <td>control</td>\n",
       "      <td>receive</td>\n",
       "      <td>template</td>\n",
       "      <td>professor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 7 - Top Words</th>\n",
       "      <td>page</td>\n",
       "      <td>served</td>\n",
       "      <td>web</td>\n",
       "      <td>directed</td>\n",
       "      <td>help</td>\n",
       "      <td>machine</td>\n",
       "      <td>use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 8 - Top Words</th>\n",
       "      <td>programming</td>\n",
       "      <td>student</td>\n",
       "      <td>courses</td>\n",
       "      <td>degree</td>\n",
       "      <td>ms</td>\n",
       "      <td>school</td>\n",
       "      <td>requires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 9 - Top Words</th>\n",
       "      <td>cas</td>\n",
       "      <td>courses</td>\n",
       "      <td>ca</td>\n",
       "      <td>resources</td>\n",
       "      <td>teaching</td>\n",
       "      <td>time</td>\n",
       "      <td>quarterly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 10 - Top Words</th>\n",
       "      <td>please</td>\n",
       "      <td>template</td>\n",
       "      <td>simulated</td>\n",
       "      <td>robotics</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>control</td>\n",
       "      <td>use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 11 - Top Words</th>\n",
       "      <td>artificial</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>artificial</td>\n",
       "      <td>professor</td>\n",
       "      <td>faculty</td>\n",
       "      <td>laboratory</td>\n",
       "      <td>machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 12 - Top Words</th>\n",
       "      <td>control</td>\n",
       "      <td>robotics</td>\n",
       "      <td>project</td>\n",
       "      <td>humanities</td>\n",
       "      <td>lab</td>\n",
       "      <td>motions</td>\n",
       "      <td>multi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 13 - Top Words</th>\n",
       "      <td>paper</td>\n",
       "      <td>learn</td>\n",
       "      <td>machine</td>\n",
       "      <td>machine</td>\n",
       "      <td>processes</td>\n",
       "      <td>language</td>\n",
       "      <td>structure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 14 - Top Words</th>\n",
       "      <td>pm</td>\n",
       "      <td>network</td>\n",
       "      <td>use</td>\n",
       "      <td>data</td>\n",
       "      <td>email</td>\n",
       "      <td>student</td>\n",
       "      <td>computer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  1             2            3           4  \\\n",
       "Cluster 0 - Top Words       control      teaching  combination       links   \n",
       "Cluster 1 - Top Words   application     deadlines       online      please   \n",
       "Cluster 2 - Top Words          list             b      project           p   \n",
       "Cluster 3 - Top Words     professor     professor      faculty      secure   \n",
       "Cluster 4 - Top Words    admissions          skip     computer      search   \n",
       "Cluster 5 - Top Words       motions         learn     robotics   dynamical   \n",
       "Cluster 6 - Top Words      robotics        design   humanities     control   \n",
       "Cluster 7 - Top Words          page        served          web    directed   \n",
       "Cluster 8 - Top Words   programming       student      courses      degree   \n",
       "Cluster 9 - Top Words           cas       courses           ca   resources   \n",
       "Cluster 10 - Top Words       please      template    simulated    robotics   \n",
       "Cluster 11 - Top Words   artificial  intelligence   artificial   professor   \n",
       "Cluster 12 - Top Words      control      robotics      project  humanities   \n",
       "Cluster 13 - Top Words        paper         learn      machine     machine   \n",
       "Cluster 14 - Top Words           pm       network          use        data   \n",
       "\n",
       "                                   5           6            7  \n",
       "Cluster 0 - Top Words         fields   dynamical      updated  \n",
       "Cluster 1 - Top Words     submitting  admissions           ph  \n",
       "Cluster 2 - Top Words      practical    training  programming  \n",
       "Cluster 3 - Top Words     humanities    focusing     computer  \n",
       "Cluster 4 - Top Words         campus       gates     building  \n",
       "Cluster 5 - Top Words   demonstrated    modeling        based  \n",
       "Cluster 6 - Top Words        receive    template    professor  \n",
       "Cluster 7 - Top Words           help     machine          use  \n",
       "Cluster 8 - Top Words             ms      school     requires  \n",
       "Cluster 9 - Top Words       teaching        time    quarterly  \n",
       "Cluster 10 - Top Words      reviewed     control          use  \n",
       "Cluster 11 - Top Words       faculty  laboratory      machine  \n",
       "Cluster 12 - Top Words           lab     motions        multi  \n",
       "Cluster 13 - Top Words     processes    language    structure  \n",
       "Cluster 14 - Top Words         email     student     computer  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map -> {code: token_list}\n",
    "tokens_lc_map = to_tokens_map(codecontent_map_lc)\n",
    "# map -> {code: stem_list}\n",
    "stems_lc_map = to_stems_map(codecontent_map_lc)\n",
    "\n",
    "# total vocabulary, list of tokens\n",
    "totalvocab_lc_stemmed = [stem for key in codecontent_map_lc for stem in stems_lc_map[key]]\n",
    "# total vocabulary, list of stems\n",
    "totalvocab_lc_tokenized = [stem for key in codecontent_map_lc for stem in tokens_lc_map[key]]\n",
    "\n",
    "vocab_lc_frame = pd.DataFrame({'words': totalvocab_lc_tokenized}, index = totalvocab_lc_stemmed)\n",
    "terms_lc = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# sort cluster centers by proximity to centroid\n",
    "order_centroids_lc = kmeans.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "num_clusters_lc = len(set(kmeans_labels_lc))\n",
    "words_matrix_lc = [None] * num_clusters_lc\n",
    "top_n = 7\n",
    "\n",
    "for i in range(num_clusters_lc):\n",
    "    cluster_chart = [vocab_lc_frame.ix[terms_lc[ind].split(' ')].values.tolist()[0][0] for ind in order_centroids_lc[i,:top_n]]\n",
    "    words_matrix_lc[i] = cluster_chart\n",
    "    \n",
    "pd.DataFrame(\n",
    "    words_matrix_lc, \n",
    "    index = [\"Cluster \" + str(i) + \" - Top Words\" for i in range(num_clusters_lc)],\n",
    "    columns = list(range(1, top_n+1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Plot\n",
    "Applying t-SNE for dimensionality reduction. We need two dimensional vectors for visualization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\"seamless=\"seamless\" src=\"https://plot.ly/~chrispolo/74.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsne = TSNE(n_components=2, random_state=1)\n",
    "twodim_docs_lc = tsne.fit_transform(dist_lc)\n",
    "\n",
    "clusters_colors_lc = [ get_color(i) for i in kmeans_labels_lc]\n",
    "\n",
    "k_tsne_data_lc = scatter_plot(twodim_docs_lc, word_labels=urls_lc, colors=clusters_colors_lc)\n",
    "py.iplot(k_tsne_data_lc, filename=\"K-Means listcostraint - Doc Clustering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <a href=\"https://plot.ly/~chrispolo/74\" \n",
    "        target=\"_blank\" title=\"y\" \n",
    "        style=\"display: block; text-align: center;\">\n",
    "            <img src=\"../dataset/img/lc_docs_wordvectors_scatter_plot_KMEANS.png\" \n",
    "                alt=\"y\" style=\"max-width: 100%;width: 1121px;\"  \n",
    "                width=\"100%\" onerror=\"this.onerror=null;this.src='https://plot.ly/404';\" />\n",
    "    </a>\n",
    "    <script data-plotly=\"chrispolo:74\"  src=\"https://plot.ly/embed.js\" async></script>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Evaluating the performance of a clustering algorithm is not as trivial as counting the number of errors or the precision and recall of a supervised classification algorithm. In particular any evaluation metric should not take the absolute values of the cluster labels into account but rather if this clustering define separations of the data similar to some ground truth set of classes or satisfying some assumption such that members belong to the same class are more similar that members of different classes according to some similarity metric.\n",
    "\n",
    "See the [scikit-learn documentaion](http://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation \"ti\") for futher information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters found manually for no-costraint documents: 15\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, -1]\n",
      "\n",
      "Clusters found manually for list-costraint documents: 14\n",
      "[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, -1]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gt = GroundTruth(os.getcwd() + \"/../dataset/\" + site + \"/ground_truth/urlToMembership.txt\")\n",
    "ground_truth_lc = [int(gt.get_groundtruth(urlmap_lc[key])) for key in codecontent_map_lc]\n",
    "\n",
    "gt = GroundTruth(os.getcwd() + \"/../dataset/\" + site + \"/ground_truth/urlToMembership.txt\")\n",
    "ground_truth_nc = [int(gt.get_groundtruth(urlmap_nc[key])) for key in codecontent_map_nc]\n",
    "\n",
    "print(\"Clusters found manually for no-costraint documents:\", len(set(ground_truth_nc)))\n",
    "print([label for label in set(ground_truth_nc)])\n",
    "print()\n",
    "print(\"Clusters found manually for list-costraint documents:\", len(set(ground_truth_lc)))\n",
    "print([label for label in set(ground_truth_lc)])\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN and HDBSCAN\n",
    "Applying other clustering algorithm for evaluation purposes.\n",
    "\n",
    "**DBSCAN** - Density-Based Spatial Clustering of Applications with Noise. Finds core samples of high density and expands clusters from them. Good for data which contains clusters of similar density.\n",
    "\n",
    "**params**:\n",
    "\n",
    "- **eps** : The maximum distance between two samples for them to be considered as in the same neighborhood.\n",
    "- **min_samples** : The number of samples (or total weight) in a neighborhood for a point to be considered as a core point. This includes the point itself.\n",
    "\n",
    "\n",
    "**HDBSCAN** - Hierarchical Density-Based Spatial Clustering of Applications with Noise. Performs DBSCAN over varying epsilon values and integrates the result to find a clustering that gives the best stability over epsilon. This allows HDBSCAN to find clusters of varying densities (unlike DBSCAN), and be more robust to parameter selection.\n",
    "\n",
    "**params**:\n",
    "\n",
    "- **min_cluster_size** : minimum nodes to form a cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  No-costraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters found with DBSCAN: 11\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, -1]\n",
      "\n",
      "\n",
      "Clusters found with HDBSCAN: 15\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, -1]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dbscan = DBSCAN(eps=0.3, min_samples=5)\n",
    "dbscan_labels_nc = dbscan.fit_predict(tfidf_matrix_nc)\n",
    "\n",
    "print(\"Clusters found with DBSCAN:\", len(set(dbscan_labels_nc)))\n",
    "print ([label for label in set(dbscan_labels_nc)])\n",
    "print(\"\\n\")\n",
    "\n",
    "hdbscan = HDBSCAN(min_cluster_size=15)\n",
    "hdbscan_labels_nc = hdbscan.fit_predict(tfidf_matrix_nc)\n",
    "\n",
    "print(\"Clusters found with HDBSCAN:\", len(set(hdbscan_labels_nc)))\n",
    "print([label for label in set(hdbscan_labels_nc)])\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List-costraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters found with DBSCAN: 5\n",
      "[0, 1, 2, 3, -1]\n",
      "\n",
      "\n",
      "Clusters found with HDBSCAN: 4\n",
      "[0, 1, 2, -1]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dbscan = DBSCAN(eps=0.5, min_samples=3)\n",
    "dbscan_labels_lc = dbscan.fit_predict(tfidf_matrix_lc)\n",
    "\n",
    "print(\"Clusters found with DBSCAN:\", len(set(dbscan_labels_lc)))\n",
    "print ([label for label in set(dbscan_labels_lc)])\n",
    "print(\"\\n\")\n",
    "\n",
    "hdbscan = HDBSCAN(min_cluster_size=5)\n",
    "hdbscan_labels_lc = hdbscan.fit_predict(tfidf_matrix_lc)\n",
    "\n",
    "print(\"Clusters found with HDBSCAN:\", len(set(hdbscan_labels_lc)))\n",
    "print([label for label in set(hdbscan_labels_lc)])\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics:\n",
    "\n",
    "- **Homogeneity**: each cluster contains only members of a single class\n",
    "\n",
    "\n",
    "- **Completeness**: all members of a given class are assigned to the same cluster\n",
    "\n",
    "\n",
    "- **Adjusted Rand index**: Given the knowledge of the *ground truth* class assignments and our clustering algorithm assignments of the same samples, the adjusted Rand index is a function that measures the similarity of the two assignments, ignoring permutations and with chance normalization\n",
    "\n",
    "\n",
    "- **V-measure**: The V-measure is actually equivalent to the mutual information (NMI) discussed above normalized by the sum of the label entropies\n",
    "\n",
    "\n",
    "- **Mutual Information based scores**: Given the knowledge of the ground truth class assignments and our clustering algorithm assignments of the same samples, the Mutual Information is a function that measures the agreement of the two assignments, ignoring permutations. Two different normalized versions of this measure are available, Normalized Mutual Information(NMI) and Adjusted Mutual Information(AMI). NMI is often used in the literature while AMI was proposed more recently and is normalized against chance\n",
    "\n",
    "\n",
    "- **Silhouette**: If the ground truth labels are not known, evaluation must be performed using the model itself. The Silhouette Coefficient is an example of such an evaluation, where a higher Silhouette Coefficient score relates to a model with better defined clusters. The score is bounded between -1 for incorrect clustering and +1 for highly dense clustering. Scores around zero indicate overlapping clusters. The score is higher when clusters are dense and well separated, which relates to a standard concept of a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Homogeneity</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>V-Measure score</th>\n",
       "      <th>Adjusted Rand index</th>\n",
       "      <th>Mutual Information</th>\n",
       "      <th>Silhouette</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NoCostraint - DBSCAN</th>\n",
       "      <td>0.258393</td>\n",
       "      <td>0.343509</td>\n",
       "      <td>0.294933</td>\n",
       "      <td>0.020787</td>\n",
       "      <td>0.240300</td>\n",
       "      <td>0.098145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoCostraint - HDBSCAN</th>\n",
       "      <td>0.301496</td>\n",
       "      <td>0.278424</td>\n",
       "      <td>0.289501</td>\n",
       "      <td>0.008851</td>\n",
       "      <td>0.252128</td>\n",
       "      <td>0.091613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoCostraint - K-MEANS</th>\n",
       "      <td>0.601448</td>\n",
       "      <td>0.465157</td>\n",
       "      <td>0.524595</td>\n",
       "      <td>0.263939</td>\n",
       "      <td>0.448893</td>\n",
       "      <td>0.270393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ListCostraint - DBSCAN</th>\n",
       "      <td>0.087603</td>\n",
       "      <td>0.392448</td>\n",
       "      <td>0.143234</td>\n",
       "      <td>0.010232</td>\n",
       "      <td>0.032697</td>\n",
       "      <td>-0.118799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ListCostraint - HDBSCAN</th>\n",
       "      <td>0.182668</td>\n",
       "      <td>0.380153</td>\n",
       "      <td>0.246763</td>\n",
       "      <td>0.068729</td>\n",
       "      <td>0.132592</td>\n",
       "      <td>0.084066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ListCostraint - K-MEANS</th>\n",
       "      <td>0.543627</td>\n",
       "      <td>0.572597</td>\n",
       "      <td>0.557736</td>\n",
       "      <td>0.216668</td>\n",
       "      <td>0.415685</td>\n",
       "      <td>0.173217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Homogeneity  Completeness  V-Measure score  \\\n",
       "NoCostraint - DBSCAN        0.258393      0.343509         0.294933   \n",
       "NoCostraint - HDBSCAN       0.301496      0.278424         0.289501   \n",
       "NoCostraint - K-MEANS       0.601448      0.465157         0.524595   \n",
       "ListCostraint - DBSCAN      0.087603      0.392448         0.143234   \n",
       "ListCostraint - HDBSCAN     0.182668      0.380153         0.246763   \n",
       "ListCostraint - K-MEANS     0.543627      0.572597         0.557736   \n",
       "\n",
       "                         Adjusted Rand index  Mutual Information  Silhouette  \n",
       "NoCostraint - DBSCAN                0.020787            0.240300    0.098145  \n",
       "NoCostraint - HDBSCAN               0.008851            0.252128    0.091613  \n",
       "NoCostraint - K-MEANS               0.263939            0.448893    0.270393  \n",
       "ListCostraint - DBSCAN              0.010232            0.032697   -0.118799  \n",
       "ListCostraint - HDBSCAN             0.068729            0.132592    0.084066  \n",
       "ListCostraint - K-MEANS             0.216668            0.415685    0.173217  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame([\n",
    "        [\n",
    "            # dbscan nocostraint\n",
    "            metrics.homogeneity_score(ground_truth_nc, dbscan_labels_nc),\n",
    "            metrics.completeness_score(ground_truth_nc, dbscan_labels_nc),\n",
    "            metrics.v_measure_score(ground_truth_nc, dbscan_labels_nc),\n",
    "            metrics.adjusted_rand_score(ground_truth_nc, dbscan_labels_nc),\n",
    "            metrics.adjusted_mutual_info_score(ground_truth_nc, dbscan_labels_nc),\n",
    "            metrics.silhouette_score(tfidf_matrix_nc, dbscan_labels_nc, metric='euclidean')\n",
    "        ],\n",
    "        [\n",
    "            # hdbscan nocostraint\n",
    "            metrics.homogeneity_score(ground_truth_nc, hdbscan_labels_nc),\n",
    "            metrics.completeness_score(ground_truth_nc, hdbscan_labels_nc),\n",
    "            metrics.v_measure_score(ground_truth_nc, hdbscan_labels_nc),\n",
    "            metrics.adjusted_rand_score(ground_truth_nc, hdbscan_labels_nc),\n",
    "            metrics.adjusted_mutual_info_score(ground_truth_nc, hdbscan_labels_nc),\n",
    "            metrics.silhouette_score(tfidf_matrix_nc, hdbscan_labels_nc, metric='euclidean')\n",
    "        ],\n",
    "        [\n",
    "            # kmeans nocostraint\n",
    "            metrics.homogeneity_score(ground_truth_nc, kmeans_labels_nc),\n",
    "            metrics.completeness_score(ground_truth_nc, kmeans_labels_nc),\n",
    "            metrics.v_measure_score(ground_truth_nc, kmeans_labels_nc),\n",
    "            metrics.adjusted_rand_score(ground_truth_nc, kmeans_labels_nc),\n",
    "            metrics.adjusted_mutual_info_score(ground_truth_nc, kmeans_labels_nc),\n",
    "            metrics.silhouette_score(tfidf_matrix_nc, kmeans_labels_nc, metric='euclidean')\n",
    "        ],\n",
    "        [\n",
    "            # dbscan listcostraint\n",
    "            metrics.homogeneity_score(ground_truth_lc, dbscan_labels_lc),\n",
    "            metrics.completeness_score(ground_truth_lc, dbscan_labels_lc),\n",
    "            metrics.v_measure_score(ground_truth_lc, dbscan_labels_lc),\n",
    "            metrics.adjusted_rand_score(ground_truth_lc, dbscan_labels_lc),\n",
    "            metrics.adjusted_mutual_info_score(ground_truth_lc, dbscan_labels_lc),\n",
    "            metrics.silhouette_score(tfidf_matrix_lc, dbscan_labels_lc, metric='euclidean')\n",
    "        ],\n",
    "        [\n",
    "            # hdbscan listcostraint\n",
    "            metrics.homogeneity_score(ground_truth_lc, hdbscan_labels_lc),\n",
    "            metrics.completeness_score(ground_truth_lc, hdbscan_labels_lc),\n",
    "            metrics.v_measure_score(ground_truth_lc, hdbscan_labels_lc),\n",
    "            metrics.adjusted_rand_score(ground_truth_lc, hdbscan_labels_lc),\n",
    "            metrics.adjusted_mutual_info_score(ground_truth_lc, hdbscan_labels_lc),\n",
    "            metrics.silhouette_score(tfidf_matrix_lc, hdbscan_labels_lc, metric='euclidean')\n",
    "        ],\n",
    "        [\n",
    "            # kmeans listcostraint\n",
    "            metrics.homogeneity_score(ground_truth_lc, kmeans_labels_lc),\n",
    "            metrics.completeness_score(ground_truth_lc, kmeans_labels_lc),\n",
    "            metrics.v_measure_score(ground_truth_lc, kmeans_labels_lc),\n",
    "            metrics.adjusted_rand_score(ground_truth_lc, kmeans_labels_lc),\n",
    "            metrics.adjusted_mutual_info_score(ground_truth_lc, kmeans_labels_lc),\n",
    "            metrics.silhouette_score(tfidf_matrix_lc, kmeans_labels_lc, metric='euclidean')\n",
    "        ]],\n",
    "        index=[\n",
    "            \"NoCostraint - DBSCAN\", \n",
    "            \"NoCostraint - HDBSCAN\", \n",
    "            \"NoCostraint - K-MEANS\", \n",
    "            \"ListCostraint - DBSCAN\", \n",
    "            \"ListCostraint - HDBSCAN\", \n",
    "            \"ListCostraint - K-MEANS\"\n",
    "        ],\n",
    "        columns=[\n",
    "            \"Homogeneity\", \n",
    "            \"Completeness\", \n",
    "            \"V-Measure score\", \n",
    "            \"Adjusted Rand index\", \n",
    "            \"Mutual Information\",\n",
    "            \"Silhouette\"\n",
    "        ])\n",
    "\n",
    "metrics_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
