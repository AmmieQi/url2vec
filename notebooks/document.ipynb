{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "from urlembed.util.plotter import *\n",
    "from urlembed.util.seqmanager import *\n",
    "\n",
    "from sklearn import metrics\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from __future__ import print_function\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is defined **term frequency - inverse document frequency** (tf-idf) vectorizer parameters and then convert the documents (web pages) list into a tf-idf matrix.\n",
    "\n",
    "To get a Tf-idf matrix, first count word occurrences by document. This is transformed into a **document-term matrix** (dtm).![Alt text](http://www.codeproject.com/KB/WPF/NNMFSearchResultClusterin/table.jpg \"Very nice\")\n",
    "\n",
    "This is also just called a term frequency matrix.\n",
    "Then apply the term frequency-inverse document frequency weighting: words that occur frequently within a document but not frequently within the corpus receive a higher weighting as these words are assumed to contain more meaning in relation to the document.\n",
    "\n",
    "A couple things to note about the parameters defined below:\n",
    "\n",
    "**max_df**: this is the maximum frequency within the documents a given feature can have to be used in the tfi-idf matrix. If the term is in greater than 80% of the documents it probably cares little meanining\n",
    "\n",
    "**min_idf**: this could be an integer (e.g. 5) and the term would have to be in at least 5 of the documents to be considered. Here I pass 0.1; the term must be in at least 10% of the document.\n",
    "\n",
    "**ngram_range**: this just means I'll look at unigrams, bigrams and trigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_df = 0.8,\n",
    "    max_features = 200000,\n",
    "    min_df = 0.1,\n",
    "    stop_words = 'english',\n",
    "    use_idf = True,\n",
    "    tokenizer = tokenize_and_stem,\n",
    "    ngram_range = (1,3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The crawling proccess has been done in two different ways:\n",
    "\n",
    "- **No costraint**: the crawler follows a random outlink from all of the outlinks in a given page\n",
    "- **List costraint**: the crawler follows a random outlink but only from the outlinks in \"lists\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No-costraint documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nocostraint_path = os.getcwd() + \"/../dataset/cs.illinois.edu_NoConstraint.words1000.depth10/\"\n",
    "vertex_nc_path   = nocostraint_path + \"vertex.txt\"\n",
    "map_nc_path      = nocostraint_path + \"urlsMap.txt\"\n",
    "\n",
    "codecontent_map_nc = get_content_map(vertex_nc_path)\n",
    "urlmap_nc          = get_urlmap(map_nc_path)\n",
    "\n",
    "documents_nc = [codecontent_map_nc[key] for key in codecontent_map_nc]\n",
    "codes_nc     = [key for key in codecontent_map_nc]\n",
    "urls_nc      = [urlmap_nc[key] for key in codecontent_map_nc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine-Similarity\n",
    "Cosine similarity is measured against the tf-idf matrix and can be used to generate a measure of similarity between each document and the other documents in the corpus.\n",
    "\n",
    "Subtracting it from 1 provides cosine distance which I will use for plotting on a euclidean (2-dimensional) plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              \n",
      "documents  728\n",
      "terms      433\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_matrix_nc = tfidf_vectorizer.fit_transform(documents_nc)\n",
    "dist_nc = 1 - cosine_similarity(tfidf_matrix_nc)\n",
    "\n",
    "print(pd.DataFrame(\n",
    "        {\"documents\":tfidf_matrix_nc.shape[0], \"terms\":tfidf_matrix_nc.shape[1]}, \n",
    "        index=[\"\"]).T)\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering on No-costraint documents\n",
    "#### K-Means\n",
    "\n",
    "K-means initializes with a pre-determined number of clusters. Each observation is assigned to a cluster (cluster assignment) so as to minimize the within cluster sum of squares. Next, the mean of the clustered observations is calculated and used as the new cluster centroid. Then, observations are reassigned to clusters and centroids recalculated in an iterative process until the algorithm reaches convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>john deere scholarship in computer science dep...</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>jump trading scholars department of computer s...</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rockwell collins scholarship department of com...</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spot trading scholarship department of compute...</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>illinois cyber security scholars program icssp...</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document code\n",
       "8  john deere scholarship in computer science dep...  344\n",
       "8  jump trading scholars department of computer s...  345\n",
       "8  rockwell collins scholarship department of com...  346\n",
       "8  spot trading scholarship department of compute...  347\n",
       "8  illinois cyber security scholars program icssp...  340"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=15)\n",
    "kmeans_labels_nc = kmeans.fit_predict(tfidf_matrix_nc)\n",
    "\n",
    "docs_nc = { \n",
    "    'code': codes_nc,\n",
    "    'document': documents_nc\n",
    "}\n",
    "frame_nc = pd.DataFrame(docs_nc, index=[kmeans_labels_nc] , columns=['document', 'code'])\n",
    "\n",
    "frame_nc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic modeling\n",
    "Some fancy indexing and sorting on each cluster to identify which are the top n words that are nearest to the cluster centroid. This gives an idea of the main topic of each the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cluster 0 - Top Words</th>\n",
       "      <td>media</td>\n",
       "      <td>moone</td>\n",
       "      <td>professor</td>\n",
       "      <td>s</td>\n",
       "      <td>awards</td>\n",
       "      <td>videos</td>\n",
       "      <td>featured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 1 - Top Words</th>\n",
       "      <td>ph</td>\n",
       "      <td>ph</td>\n",
       "      <td>d</td>\n",
       "      <td>thesis</td>\n",
       "      <td>requirement</td>\n",
       "      <td>form</td>\n",
       "      <td>programs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 2 - Top Words</th>\n",
       "      <td>curriculum</td>\n",
       "      <td>research</td>\n",
       "      <td>news</td>\n",
       "      <td>news</td>\n",
       "      <td>offered</td>\n",
       "      <td>class</td>\n",
       "      <td>please</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 3 - Top Words</th>\n",
       "      <td>win</td>\n",
       "      <td>awards</td>\n",
       "      <td>directory</td>\n",
       "      <td>home</td>\n",
       "      <td>directory</td>\n",
       "      <td>related</td>\n",
       "      <td>story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 4 - Top Words</th>\n",
       "      <td>chair</td>\n",
       "      <td>awards</td>\n",
       "      <td>siebel</td>\n",
       "      <td>m</td>\n",
       "      <td>s</td>\n",
       "      <td>ieee</td>\n",
       "      <td>siebel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 5 - Top Words</th>\n",
       "      <td>security</td>\n",
       "      <td>networks</td>\n",
       "      <td>information</td>\n",
       "      <td>s</td>\n",
       "      <td>work</td>\n",
       "      <td>social</td>\n",
       "      <td>professor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 6 - Top Words</th>\n",
       "      <td>graduate</td>\n",
       "      <td>ms</td>\n",
       "      <td>requirement</td>\n",
       "      <td>programs</td>\n",
       "      <td>graduate</td>\n",
       "      <td>hours</td>\n",
       "      <td>bs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 7 - Top Words</th>\n",
       "      <td>parallel</td>\n",
       "      <td>performance</td>\n",
       "      <td>parallel</td>\n",
       "      <td>software</td>\n",
       "      <td>high</td>\n",
       "      <td>programs</td>\n",
       "      <td>professor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 8 - Top Words</th>\n",
       "      <td>undergraduate</td>\n",
       "      <td>undergraduate</td>\n",
       "      <td>scholarship</td>\n",
       "      <td>programs</td>\n",
       "      <td>students</td>\n",
       "      <td>advising</td>\n",
       "      <td>academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 9 - Top Words</th>\n",
       "      <td>siebel</td>\n",
       "      <td>siebel</td>\n",
       "      <td>center</td>\n",
       "      <td>office</td>\n",
       "      <td>resources</td>\n",
       "      <td>scholars</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 10 - Top Words</th>\n",
       "      <td>s</td>\n",
       "      <td>said</td>\n",
       "      <td>school</td>\n",
       "      <td>programs</td>\n",
       "      <td>work</td>\n",
       "      <td>team</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 11 - Top Words</th>\n",
       "      <td>awards</td>\n",
       "      <td>distinguished</td>\n",
       "      <td>service</td>\n",
       "      <td>outstanding</td>\n",
       "      <td>cs</td>\n",
       "      <td>member</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 12 - Top Words</th>\n",
       "      <td>data</td>\n",
       "      <td>using</td>\n",
       "      <td>s</td>\n",
       "      <td>work</td>\n",
       "      <td>models</td>\n",
       "      <td>information</td>\n",
       "      <td>said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 13 - Top Words</th>\n",
       "      <td>applications</td>\n",
       "      <td>graduate</td>\n",
       "      <td>programs</td>\n",
       "      <td>fellowship</td>\n",
       "      <td>ms</td>\n",
       "      <td>deadlines</td>\n",
       "      <td>degrees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 14 - Top Words</th>\n",
       "      <td>office</td>\n",
       "      <td>contact</td>\n",
       "      <td>contact</td>\n",
       "      <td>office</td>\n",
       "      <td>directory</td>\n",
       "      <td>staff</td>\n",
       "      <td>staff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    1              2            3  \\\n",
       "Cluster 0 - Top Words           media          moone    professor   \n",
       "Cluster 1 - Top Words              ph             ph            d   \n",
       "Cluster 2 - Top Words      curriculum       research         news   \n",
       "Cluster 3 - Top Words             win         awards    directory   \n",
       "Cluster 4 - Top Words           chair         awards       siebel   \n",
       "Cluster 5 - Top Words        security       networks  information   \n",
       "Cluster 6 - Top Words        graduate             ms  requirement   \n",
       "Cluster 7 - Top Words        parallel    performance     parallel   \n",
       "Cluster 8 - Top Words   undergraduate  undergraduate  scholarship   \n",
       "Cluster 9 - Top Words          siebel         siebel       center   \n",
       "Cluster 10 - Top Words              s           said       school   \n",
       "Cluster 11 - Top Words         awards  distinguished      service   \n",
       "Cluster 12 - Top Words           data          using            s   \n",
       "Cluster 13 - Top Words   applications       graduate     programs   \n",
       "Cluster 14 - Top Words         office        contact      contact   \n",
       "\n",
       "                                  4            5            6          7  \n",
       "Cluster 0 - Top Words             s       awards       videos   featured  \n",
       "Cluster 1 - Top Words        thesis  requirement         form   programs  \n",
       "Cluster 2 - Top Words          news      offered        class     please  \n",
       "Cluster 3 - Top Words          home    directory      related      story  \n",
       "Cluster 4 - Top Words             m            s         ieee     siebel  \n",
       "Cluster 5 - Top Words             s         work       social  professor  \n",
       "Cluster 6 - Top Words      programs     graduate        hours         bs  \n",
       "Cluster 7 - Top Words      software         high     programs  professor  \n",
       "Cluster 8 - Top Words      programs     students     advising   academic  \n",
       "Cluster 9 - Top Words        office    resources     scholars          m  \n",
       "Cluster 10 - Top Words     programs         work         team       high  \n",
       "Cluster 11 - Top Words  outstanding           cs       member          s  \n",
       "Cluster 12 - Top Words         work       models  information       said  \n",
       "Cluster 13 - Top Words   fellowship           ms    deadlines    degrees  \n",
       "Cluster 14 - Top Words       office    directory        staff      staff  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map -> {code: token_list}\n",
    "tokens_nc_map = to_tokens_map(codecontent_map_nc)\n",
    "# map -> {code: stem_list}\n",
    "stems_nc_map = to_stems_map(codecontent_map_nc)\n",
    "\n",
    "# total vocabulary, list of tokens\n",
    "totalvocab_nc_stemmed = [stem for key in codecontent_map_nc for stem in stems_nc_map[key]]\n",
    "# total vocabulary, list of stems\n",
    "totalvocab_nc_tokenized = [stem for key in codecontent_map_nc for stem in tokens_nc_map[key]]\n",
    "\n",
    "vocab_nc_frame = pd.DataFrame({'words': totalvocab_nc_tokenized}, index = totalvocab_nc_stemmed)\n",
    "terms_nc = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# sort cluster centers by proximity to centroid\n",
    "order_centroids_nc = kmeans.cluster_centers_.argsort()[:,::-1]\n",
    "\n",
    "num_clusters_nc = len(set(kmeans_labels_nc))\n",
    "words_matrix_nc = [None] * num_clusters_nc\n",
    "top_n = 7\n",
    "\n",
    "for i in range(num_clusters_nc):\n",
    "    cluster_chart = [vocab_nc_frame.ix[terms_nc[ind].split(' ')].values.tolist()[0][0] \n",
    "                     for ind in order_centroids_nc[i,:top_n]]\n",
    "    words_matrix_nc[i] = cluster_chart\n",
    "    \n",
    "pd.DataFrame(\n",
    "    words_matrix_nc, \n",
    "    index = [\"Cluster \" + str(i) + \" - Top Words\" for i in range(num_clusters_nc)],\n",
    "    columns = list(range(1, top_n+1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Plot\n",
    "Applying t-SNE for dimensionality reduction. We need two dimensional vectors for visualization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state=1)\n",
    "twodim_docs_nc = tsne.fit_transform(dist_nc)\n",
    "# tfidf_matrix_dense_nc = tfidf_matrix_nc.todense()\n",
    "# docs_vecs_nc = np.array([tfidf_matrix_dense_nc[i].A1 for i in range(len(tfidf_matrix_dense_nc))])\n",
    "clusters_colors_nc = [ get_color(i) for i in kmeans_labels_nc]\n",
    "\n",
    "kmeans_data = scatter_plot(twodim_docs_nc, word_labels=urls_nc, colors=clusters_colors_nc)\n",
    "py.iplot(kmeans_data, filename=\"K-Means t-SNE nocostraint - Doc Clustering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <a href=\"https://plot.ly/~chrispolo/70\" \n",
    "        target=\"_blank\" title=\"y\" \n",
    "        style=\"display: block; text-align: center;\">\n",
    "            <img src=\"../dataset/img/nc_docs_wordvectors_scatter_plot_KMEANS.png\" \n",
    "                alt=\"y\" style=\"max-width: 100%;width: 1121px;\"  \n",
    "                width=\"100%\" onerror=\"this.onerror=null;this.src='https://plot.ly/404';\" />\n",
    "    </a>\n",
    "    <script data-plotly=\"chrispolo:70\"  src=\"https://plot.ly/embed.js\" async></script>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List-costraint documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listcostraint_path = os.getcwd() + \"/../dataset/cs.illinois.edu_ListConstraint.words1000.depth10/\"\n",
    "vertex_lc_path     = listcostraint_path + \"vertex.txt\"\n",
    "map_lc_path        = listcostraint_path + \"urlsMap.txt\"\n",
    "\n",
    "codecontent_map_lc = get_content_map(vertex_lc_path)\n",
    "urlmap_lc = get_urlmap(map_lc_path)\n",
    "\n",
    "# document list\n",
    "documents_lc = [codecontent_map_lc[key] for key in codecontent_map_lc]\n",
    "codes_lc     = [key for key in codecontent_map_lc]\n",
    "urls_lc      = [urlmap_lc[key] for key in codecontent_map_lc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine-Similarity\n",
    "Cosine similarity is measured against the tf-idf matrix and can be used to generate a measure of similarity between each document and the other documents in the corpus.\n",
    "\n",
    "Subtracting it from 1 provides cosine distance which I will use for plotting on a euclidean (2-dimensional) plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               \n",
      "documents  1022\n",
      "terms       370\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_matrix_lc = tfidf_vectorizer.fit_transform(documents_lc)\n",
    "\n",
    "dist_lc = 1 - cosine_similarity(tfidf_matrix_lc)\n",
    "\n",
    "print(pd.DataFrame({\"documents\":tfidf_matrix_lc.shape[0], \"terms\":tfidf_matrix_lc.shape[1]}, index=[\"\"]).T)\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering on List-costraint documents\n",
    "#### K-Means\n",
    "K-means initializes with a pre-determined number of clusters. Each observation is assigned to a cluster (cluster assignment) so as to minimize the within cluster sum of squares. Next, the mean of the clustered observations is calculated and used as the new cluster centroid. Then, observations are reassigned to clusters and centroids recalculated in an iterative process until the algorithm reaches convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>engineering at illinois my cs illinois educomp...</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>engineering at illinois my cs illinois educomp...</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>engineering at illinois my cs illinois educomp...</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>engineering at illinois my cs illinois educomp...</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>engineering at illinois my cs illinois educomp...</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document code\n",
       "8  engineering at illinois my cs illinois educomp...  344\n",
       "8  engineering at illinois my cs illinois educomp...  345\n",
       "1  engineering at illinois my cs illinois educomp...  346\n",
       "5  engineering at illinois my cs illinois educomp...  347\n",
       "2  engineering at illinois my cs illinois educomp...  340"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=15)\n",
    "kmeans_labels_lc = kmeans.fit_predict(tfidf_matrix_lc)\n",
    "docs_lc = {\n",
    "    'code': codes_lc,\n",
    "    'document': documents_lc\n",
    "}\n",
    "\n",
    "frame_lc = pd.DataFrame(docs_lc, index = [kmeans_labels_lc] , columns = ['document', 'code'])\n",
    "frame_lc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic modeling\n",
    "Some fancy indexing and sorting on each cluster to identify which are the top n words that are nearest to the cluster centroid. This gives an idea of the main topic of each the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cluster 0 - Top Words</th>\n",
       "      <td>data</td>\n",
       "      <td>methods</td>\n",
       "      <td>c</td>\n",
       "      <td>information</td>\n",
       "      <td>languages</td>\n",
       "      <td>applies</td>\n",
       "      <td>processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 1 - Top Words</th>\n",
       "      <td>primary</td>\n",
       "      <td>primary</td>\n",
       "      <td>primary</td>\n",
       "      <td>research</td>\n",
       "      <td>professor</td>\n",
       "      <td>offices</td>\n",
       "      <td>offices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 2 - Top Words</th>\n",
       "      <td>edu</td>\n",
       "      <td>edu</td>\n",
       "      <td>illinois</td>\n",
       "      <td>comp</td>\n",
       "      <td>center</td>\n",
       "      <td>center</td>\n",
       "      <td>siebel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 3 - Top Words</th>\n",
       "      <td>parallel</td>\n",
       "      <td>performance</td>\n",
       "      <td>parallel</td>\n",
       "      <td>programming</td>\n",
       "      <td>software</td>\n",
       "      <td>modeling</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 4 - Top Words</th>\n",
       "      <td>undergraduate</td>\n",
       "      <td>undergraduate</td>\n",
       "      <td>programming</td>\n",
       "      <td>edu</td>\n",
       "      <td>illinois</td>\n",
       "      <td>students</td>\n",
       "      <td>advising</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 5 - Top Words</th>\n",
       "      <td>store</td>\n",
       "      <td>courses</td>\n",
       "      <td>store</td>\n",
       "      <td>curriculum</td>\n",
       "      <td>cs</td>\n",
       "      <td>courses</td>\n",
       "      <td>home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 6 - Top Words</th>\n",
       "      <td>description</td>\n",
       "      <td>topic</td>\n",
       "      <td>section</td>\n",
       "      <td>courses</td>\n",
       "      <td>curriculum</td>\n",
       "      <td>instructor</td>\n",
       "      <td>section</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 7 - Top Words</th>\n",
       "      <td>applications</td>\n",
       "      <td>graduate</td>\n",
       "      <td>programming</td>\n",
       "      <td>ms</td>\n",
       "      <td>required</td>\n",
       "      <td>ph</td>\n",
       "      <td>ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 8 - Top Words</th>\n",
       "      <td>honors</td>\n",
       "      <td>publications</td>\n",
       "      <td>honors</td>\n",
       "      <td>contacts</td>\n",
       "      <td>contacts</td>\n",
       "      <td>offices</td>\n",
       "      <td>research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 9 - Top Words</th>\n",
       "      <td>security</td>\n",
       "      <td>s</td>\n",
       "      <td>networking</td>\n",
       "      <td>working</td>\n",
       "      <td>programming</td>\n",
       "      <td>information</td>\n",
       "      <td>development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 10 - Top Words</th>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>r</td>\n",
       "      <td>t</td>\n",
       "      <td>design</td>\n",
       "      <td>programming</td>\n",
       "      <td>learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 11 - Top Words</th>\n",
       "      <td>awarded</td>\n",
       "      <td>members</td>\n",
       "      <td>s</td>\n",
       "      <td>siebel</td>\n",
       "      <td>service</td>\n",
       "      <td>outstanding</td>\n",
       "      <td>acm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 12 - Top Words</th>\n",
       "      <td>comp</td>\n",
       "      <td>siebel</td>\n",
       "      <td>center</td>\n",
       "      <td>siebel</td>\n",
       "      <td>comp</td>\n",
       "      <td>center</td>\n",
       "      <td>siebel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 13 - Top Words</th>\n",
       "      <td>data</td>\n",
       "      <td>s</td>\n",
       "      <td>new</td>\n",
       "      <td>used</td>\n",
       "      <td>information</td>\n",
       "      <td>working</td>\n",
       "      <td>projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 14 - Top Words</th>\n",
       "      <td>s</td>\n",
       "      <td>said</td>\n",
       "      <td>moone</td>\n",
       "      <td>media</td>\n",
       "      <td>working</td>\n",
       "      <td>illinois</td>\n",
       "      <td>edu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    1              2            3  \\\n",
       "Cluster 0 - Top Words            data        methods            c   \n",
       "Cluster 1 - Top Words         primary        primary      primary   \n",
       "Cluster 2 - Top Words             edu            edu     illinois   \n",
       "Cluster 3 - Top Words        parallel    performance     parallel   \n",
       "Cluster 4 - Top Words   undergraduate  undergraduate  programming   \n",
       "Cluster 5 - Top Words           store        courses        store   \n",
       "Cluster 6 - Top Words     description          topic      section   \n",
       "Cluster 7 - Top Words    applications       graduate  programming   \n",
       "Cluster 8 - Top Words          honors   publications       honors   \n",
       "Cluster 9 - Top Words        security              s   networking   \n",
       "Cluster 10 - Top Words              b              c            r   \n",
       "Cluster 11 - Top Words        awarded        members            s   \n",
       "Cluster 12 - Top Words           comp         siebel       center   \n",
       "Cluster 13 - Top Words           data              s          new   \n",
       "Cluster 14 - Top Words              s           said        moone   \n",
       "\n",
       "                                  4            5            6            7  \n",
       "Cluster 0 - Top Words   information    languages      applies   processing  \n",
       "Cluster 1 - Top Words      research    professor      offices      offices  \n",
       "Cluster 2 - Top Words          comp       center       center       siebel  \n",
       "Cluster 3 - Top Words   programming     software     modeling         high  \n",
       "Cluster 4 - Top Words           edu     illinois     students     advising  \n",
       "Cluster 5 - Top Words    curriculum           cs      courses         home  \n",
       "Cluster 6 - Top Words       courses   curriculum   instructor      section  \n",
       "Cluster 7 - Top Words            ms     required           ph           ph  \n",
       "Cluster 8 - Top Words      contacts     contacts      offices     research  \n",
       "Cluster 9 - Top Words       working  programming  information  development  \n",
       "Cluster 10 - Top Words            t       design  programming        learn  \n",
       "Cluster 11 - Top Words       siebel      service  outstanding          acm  \n",
       "Cluster 12 - Top Words       siebel         comp       center       siebel  \n",
       "Cluster 13 - Top Words         used  information      working     projects  \n",
       "Cluster 14 - Top Words        media      working     illinois          edu  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map -> {code: token_list}\n",
    "tokens_lc_map = to_tokens_map(codecontent_map_lc)\n",
    "# map -> {code: stem_list}\n",
    "stems_lc_map = to_stems_map(codecontent_map_lc)\n",
    "\n",
    "# total vocabulary, list of tokens\n",
    "totalvocab_lc_stemmed = [stem for key in codecontent_map_lc for stem in stems_lc_map[key]]\n",
    "# total vocabulary, list of stems\n",
    "totalvocab_lc_tokenized = [stem for key in codecontent_map_lc for stem in tokens_lc_map[key]]\n",
    "\n",
    "vocab_lc_frame = pd.DataFrame({'words': totalvocab_lc_tokenized}, index = totalvocab_lc_stemmed)\n",
    "terms_lc = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# sort cluster centers by proximity to centroid\n",
    "order_centroids_lc = kmeans.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "num_clusters_lc = len(set(kmeans_labels_lc))\n",
    "words_matrix_lc = [None] * num_clusters_lc\n",
    "top_n = 7\n",
    "\n",
    "for i in range(num_clusters_lc):\n",
    "    cluster_chart = [vocab_lc_frame.ix[terms_lc[ind].split(' ')].values.tolist()[0][0] for ind in order_centroids_lc[i,:top_n]]\n",
    "    words_matrix_lc[i] = cluster_chart\n",
    "    \n",
    "pd.DataFrame(\n",
    "    words_matrix_lc, \n",
    "    index = [\"Cluster \" + str(i) + \" - Top Words\" for i in range(num_clusters_lc)],\n",
    "    columns = list(range(1, top_n+1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Plot\n",
    "Applying t-SNE for dimensionality reduction. We need two dimensional vectors for visualization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state=1)\n",
    "twodim_docs_lc = tsne.fit_transform(dist_lc)\n",
    "#tfidf_matrix_lc_dense = tfidf_matrix_lc.todense()\n",
    "#docs_vecs_lc = np.array([tfidf_matrix_lc_dense[i].A1 for i in range(len(tfidf_matrix_lc_dense))])\n",
    "clusters_colors_lc = [ get_color(i) for i in kmeans_labels_lc]\n",
    "\n",
    "k_tsne_data_lc = scatter_plot(twodim_docs_lc, word_labels=urls_lc, colors=clusters_colors_lc)\n",
    "py.iplot(k_tsne_data_lc, filename=\"K-Means listcostraint - Doc Clustering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <a href=\"https://plot.ly/~chrispolo/74\" \n",
    "        target=\"_blank\" title=\"y\" \n",
    "        style=\"display: block; text-align: center;\">\n",
    "            <img src=\"../dataset/img/lc_docs_wordvectors_scatter_plot_KMEANS.png\" \n",
    "                alt=\"y\" style=\"max-width: 100%;width: 1121px;\"  \n",
    "                width=\"100%\" onerror=\"this.onerror=null;this.src='https://plot.ly/404';\" />\n",
    "    </a>\n",
    "    <script data-plotly=\"chrispolo:74\"  src=\"https://plot.ly/embed.js\" async></script>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Evaluating the performance of a clustering algorithm is not as trivial as counting the number of errors or the precision and recall of a supervised classification algorithm. In particular any evaluation metric should not take the absolute values of the cluster labels into account but rather if this clustering define separations of the data similar to some ground truth set of classes or satisfying some assumption such that members belong to the same class are more similar that members of different classes according to some similarity metric.\n",
    "\n",
    "See the [scikit-learn documentaion](http://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation \"ti\") for futher information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters found manually for no-costraint documents: 14\n",
      "[0, 1, 2, 3, 4, 6, 8, 10, 11, 12, 13, 14, 15, -1]\n",
      "\n",
      "Clusters found manually for list-costraint documents: 13\n",
      "[0, 1, 2, 3, 4, 6, 8, 10, 12, 13, 14, 15, -1]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gt = GroundTruth(os.getcwd() + \"/../dataset/ground_truth/urlToMembership.txt\")\n",
    "ground_truth_lc = [int(gt.get_groundtruth(urlmap_lc[key])) for key in codecontent_map_lc]\n",
    "\n",
    "gt = GroundTruth(os.getcwd() + \"/../dataset/ground_truth/urlToMembership.txt\")\n",
    "ground_truth_nc = [int(gt.get_groundtruth(urlmap_nc[key])) for key in codecontent_map_nc]\n",
    "\n",
    "print(\"Clusters found manually for no-costraint documents:\", len(set(ground_truth_nc)))\n",
    "print([label for label in set(ground_truth_nc)])\n",
    "print()\n",
    "print(\"Clusters found manually for list-costraint documents:\", len(set(ground_truth_lc)))\n",
    "print([label for label in set(ground_truth_lc)])\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN and HDBSCAN\n",
    "Applying other clustering algorithm for evaluation purposes.\n",
    "\n",
    "**DBSCAN** - Density-Based Spatial Clustering of Applications with Noise. Finds core samples of high density and expands clusters from them. Good for data which contains clusters of similar density.\n",
    "\n",
    "**params**:\n",
    "\n",
    "- **eps** : The maximum distance between two samples for them to be considered as in the same neighborhood.\n",
    "- **min_samples** : The number of samples (or total weight) in a neighborhood for a point to be considered as a core point. This includes the point itself.\n",
    "\n",
    "\n",
    "**HDBSCAN** - Hierarchical Density-Based Spatial Clustering of Applications with Noise. Performs DBSCAN over varying epsilon values and integrates the result to find a clustering that gives the best stability over epsilon. This allows HDBSCAN to find clusters of varying densities (unlike DBSCAN), and be more robust to parameter selection.\n",
    "\n",
    "**params**:\n",
    "\n",
    "- **min_cluster_size** : minimum nodes to form a cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  No-costraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters found with DBSCAN: 16\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, -1]\n",
      "\n",
      "\n",
      "Clusters found with HDBSCAN: 15\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, -1]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dbscan = DBSCAN(eps=0.9, min_samples=4)\n",
    "dbscan_labels_nc = dbscan.fit_predict(tfidf_matrix_nc)\n",
    "\n",
    "print(\"Clusters found with DBSCAN:\", len(set(dbscan_labels_nc)))\n",
    "print ([label for label in set(dbscan_labels_nc)])\n",
    "print(\"\\n\")\n",
    "\n",
    "hdbscan = HDBSCAN(min_cluster_size=4)\n",
    "hdbscan_labels_nc = hdbscan.fit_predict(tfidf_matrix_nc)\n",
    "\n",
    "print(\"Clusters found with HDBSCAN:\", len(set(hdbscan_labels_nc)))\n",
    "print([label for label in set(hdbscan_labels_nc)])\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List-costraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters found with DBSCAN: 14\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, -1]\n",
      "\n",
      "\n",
      "Clusters found with HDBSCAN: 13\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, -1]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dbscan = DBSCAN(eps=0.7, min_samples=4)\n",
    "dbscan_labels_lc = dbscan.fit_predict(tfidf_matrix_lc)\n",
    "\n",
    "print(\"Clusters found with DBSCAN:\", len(set(dbscan_labels_lc)))\n",
    "print ([label for label in set(dbscan_labels_lc)])\n",
    "print(\"\\n\")\n",
    "\n",
    "hdbscan = HDBSCAN(min_cluster_size=7)\n",
    "hdbscan_labels_lc = hdbscan.fit_predict(tfidf_matrix_lc)\n",
    "\n",
    "print(\"Clusters found with HDBSCAN:\", len(set(hdbscan_labels_lc)))\n",
    "print([label for label in set(hdbscan_labels_lc)])\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics:\n",
    "\n",
    "- **Homogeneity**: each cluster contains only members of a single class\n",
    "\n",
    "\n",
    "- **Completeness**: all members of a given class are assigned to the same cluster\n",
    "\n",
    "\n",
    "- **Adjusted Rand index**: Given the knowledge of the *ground truth* class assignments and our clustering algorithm assignments of the same samples, the adjusted Rand index is a function that measures the similarity of the two assignments, ignoring permutations and with chance normalization\n",
    "\n",
    "\n",
    "- **V-measure**: The V-measure is actually equivalent to the mutual information (NMI) discussed above normalized by the sum of the label entropies\n",
    "\n",
    "\n",
    "- **Mutual Information based scores**: Given the knowledge of the ground truth class assignments and our clustering algorithm assignments of the same samples, the Mutual Information is a function that measures the agreement of the two assignments, ignoring permutations. Two different normalized versions of this measure are available, Normalized Mutual Information(NMI) and Adjusted Mutual Information(AMI). NMI is often used in the literature while AMI was proposed more recently and is normalized against chance\n",
    "\n",
    "\n",
    "- **Silhouette**: If the ground truth labels are not known, evaluation must be performed using the model itself. The Silhouette Coefficient is an example of such an evaluation, where a higher Silhouette Coefficient score relates to a model with better defined clusters. The score is bounded between -1 for incorrect clustering and +1 for highly dense clustering. Scores around zero indicate overlapping clusters. The score is higher when clusters are dense and well separated, which relates to a standard concept of a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Homogeneity</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>V-Measure score</th>\n",
       "      <th>Adjusted Rand index</th>\n",
       "      <th>Mutual Information</th>\n",
       "      <th>Silhouette</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NoCostraint - DBSCAN</th>\n",
       "      <td>0.560068</td>\n",
       "      <td>0.596247</td>\n",
       "      <td>0.577592</td>\n",
       "      <td>0.407829</td>\n",
       "      <td>0.534608</td>\n",
       "      <td>0.124196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoCostraint - HDBSCAN</th>\n",
       "      <td>0.515236</td>\n",
       "      <td>0.602887</td>\n",
       "      <td>0.555626</td>\n",
       "      <td>0.386213</td>\n",
       "      <td>0.485780</td>\n",
       "      <td>0.088177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoCostraint - K-MEANS</th>\n",
       "      <td>0.761914</td>\n",
       "      <td>0.581443</td>\n",
       "      <td>0.659556</td>\n",
       "      <td>0.318361</td>\n",
       "      <td>0.558630</td>\n",
       "      <td>0.176674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ListCostraint - DBSCAN</th>\n",
       "      <td>0.570969</td>\n",
       "      <td>0.704237</td>\n",
       "      <td>0.630639</td>\n",
       "      <td>0.519670</td>\n",
       "      <td>0.556604</td>\n",
       "      <td>0.140611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ListCostraint - HDBSCAN</th>\n",
       "      <td>0.450059</td>\n",
       "      <td>0.510352</td>\n",
       "      <td>0.478313</td>\n",
       "      <td>0.193805</td>\n",
       "      <td>0.429703</td>\n",
       "      <td>0.101792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ListCostraint - K-MEANS</th>\n",
       "      <td>0.806122</td>\n",
       "      <td>0.589173</td>\n",
       "      <td>0.680781</td>\n",
       "      <td>0.429626</td>\n",
       "      <td>0.574795</td>\n",
       "      <td>0.200217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Homogeneity  Completeness  V-Measure score  \\\n",
       "NoCostraint - DBSCAN        0.560068      0.596247         0.577592   \n",
       "NoCostraint - HDBSCAN       0.515236      0.602887         0.555626   \n",
       "NoCostraint - K-MEANS       0.761914      0.581443         0.659556   \n",
       "ListCostraint - DBSCAN      0.570969      0.704237         0.630639   \n",
       "ListCostraint - HDBSCAN     0.450059      0.510352         0.478313   \n",
       "ListCostraint - K-MEANS     0.806122      0.589173         0.680781   \n",
       "\n",
       "                         Adjusted Rand index  Mutual Information  Silhouette  \n",
       "NoCostraint - DBSCAN                0.407829            0.534608    0.124196  \n",
       "NoCostraint - HDBSCAN               0.386213            0.485780    0.088177  \n",
       "NoCostraint - K-MEANS               0.318361            0.558630    0.176674  \n",
       "ListCostraint - DBSCAN              0.519670            0.556604    0.140611  \n",
       "ListCostraint - HDBSCAN             0.193805            0.429703    0.101792  \n",
       "ListCostraint - K-MEANS             0.429626            0.574795    0.200217  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame([\n",
    "        [\n",
    "            # dbscan nocostraint\n",
    "            metrics.homogeneity_score(ground_truth_nc, dbscan_labels_nc),\n",
    "            metrics.completeness_score(ground_truth_nc, dbscan_labels_nc),\n",
    "            metrics.v_measure_score(ground_truth_nc, dbscan_labels_nc),\n",
    "            metrics.adjusted_rand_score(ground_truth_nc, dbscan_labels_nc),\n",
    "            metrics.adjusted_mutual_info_score(ground_truth_nc, dbscan_labels_nc),\n",
    "            metrics.silhouette_score(tfidf_matrix_nc, dbscan_labels_nc, metric='euclidean')\n",
    "        ],\n",
    "        [\n",
    "            # hdbscan nocostraint\n",
    "            metrics.homogeneity_score(ground_truth_nc, hdbscan_labels_nc),\n",
    "            metrics.completeness_score(ground_truth_nc, hdbscan_labels_nc),\n",
    "            metrics.v_measure_score(ground_truth_nc, hdbscan_labels_nc),\n",
    "            metrics.adjusted_rand_score(ground_truth_nc, hdbscan_labels_nc),\n",
    "            metrics.adjusted_mutual_info_score(ground_truth_nc, hdbscan_labels_nc),\n",
    "            metrics.silhouette_score(tfidf_matrix_nc, hdbscan_labels_nc, metric='euclidean')\n",
    "        ],\n",
    "        [\n",
    "            # kmeans nocostraint\n",
    "            metrics.homogeneity_score(ground_truth_nc, kmeans_labels_nc),\n",
    "            metrics.completeness_score(ground_truth_nc, kmeans_labels_nc),\n",
    "            metrics.v_measure_score(ground_truth_nc, kmeans_labels_nc),\n",
    "            metrics.adjusted_rand_score(ground_truth_nc, kmeans_labels_nc),\n",
    "            metrics.adjusted_mutual_info_score(ground_truth_nc, kmeans_labels_nc),\n",
    "            metrics.silhouette_score(tfidf_matrix_nc, kmeans_labels_nc, metric='euclidean')\n",
    "        ],\n",
    "        [\n",
    "            # dbscan listcostraint\n",
    "            metrics.homogeneity_score(ground_truth_lc, dbscan_labels_lc),\n",
    "            metrics.completeness_score(ground_truth_lc, dbscan_labels_lc),\n",
    "            metrics.v_measure_score(ground_truth_lc, dbscan_labels_lc),\n",
    "            metrics.adjusted_rand_score(ground_truth_lc, dbscan_labels_lc),\n",
    "            metrics.adjusted_mutual_info_score(ground_truth_lc, dbscan_labels_lc),\n",
    "            metrics.silhouette_score(tfidf_matrix_lc, dbscan_labels_lc, metric='euclidean')\n",
    "        ],\n",
    "        [\n",
    "            # hdbscan listcostraint\n",
    "            metrics.homogeneity_score(ground_truth_lc, hdbscan_labels_lc),\n",
    "            metrics.completeness_score(ground_truth_lc, hdbscan_labels_lc),\n",
    "            metrics.v_measure_score(ground_truth_lc, hdbscan_labels_lc),\n",
    "            metrics.adjusted_rand_score(ground_truth_lc, hdbscan_labels_lc),\n",
    "            metrics.adjusted_mutual_info_score(ground_truth_lc, hdbscan_labels_lc),\n",
    "            metrics.silhouette_score(tfidf_matrix_lc, hdbscan_labels_lc, metric='euclidean')\n",
    "        ],\n",
    "        [\n",
    "            # kmeans listcostraint\n",
    "            metrics.homogeneity_score(ground_truth_lc, kmeans_labels_lc),\n",
    "            metrics.completeness_score(ground_truth_lc, kmeans_labels_lc),\n",
    "            metrics.v_measure_score(ground_truth_lc, kmeans_labels_lc),\n",
    "            metrics.adjusted_rand_score(ground_truth_lc, kmeans_labels_lc),\n",
    "            metrics.adjusted_mutual_info_score(ground_truth_lc, kmeans_labels_lc),\n",
    "            metrics.silhouette_score(tfidf_matrix_lc, kmeans_labels_lc, metric='euclidean')\n",
    "        ]],\n",
    "        index=[\n",
    "            \"NoCostraint - DBSCAN\", \n",
    "            \"NoCostraint - HDBSCAN\", \n",
    "            \"NoCostraint - K-MEANS\", \n",
    "            \"ListCostraint - DBSCAN\", \n",
    "            \"ListCostraint - HDBSCAN\", \n",
    "            \"ListCostraint - K-MEANS\"\n",
    "        ],\n",
    "        columns=[\n",
    "            \"Homogeneity\", \n",
    "            \"Completeness\", \n",
    "            \"V-Measure score\", \n",
    "            \"Adjusted Rand index\", \n",
    "            \"Mutual Information\",\n",
    "            \"Silhouette\"\n",
    "        ])\n",
    "\n",
    "metrics_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
