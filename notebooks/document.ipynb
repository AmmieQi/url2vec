{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "#import plotly.plotly as py\n",
    "#from plotly.graph_objs import *\n",
    "#from url2vec.util.plotter import *\n",
    "from url2vec.util.seqmanager import *\n",
    "\n",
    "from sklearn import metrics\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from __future__ import print_function\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# available datasets\n",
    "# cs.illinois.edu    cs.stanford.edu    eecs.mit.edu    cs.princeton.edu    cs.ox.ac.uk\n",
    "site = \"cs.illinois.edu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is defined **term frequency - inverse document frequency** (tf-idf) vectorizer parameters and then convert the documents (web pages) list into a tf-idf matrix.\n",
    "\n",
    "To get a Tf-idf matrix, first count word occurrences by document. This is transformed into a **document-term matrix** (dtm).![Alt text](http://www.codeproject.com/KB/WPF/NNMFSearchResultClusterin/table.jpg \"Very nice\")\n",
    "\n",
    "This is also just called a term frequency matrix.\n",
    "Then apply the term frequency-inverse document frequency weighting: words that occur frequently within a document but not frequently within the corpus receive a higher weighting as these words are assumed to contain more meaning in relation to the document.\n",
    "\n",
    "A couple things to note about the parameters defined below:\n",
    "\n",
    "**max_df**: this is the maximum frequency within the documents a given feature can have to be used in the tfi-idf matrix. If the term is in greater than 80% of the documents it probably cares little meanining\n",
    "\n",
    "**min_idf**: this could be an integer (e.g. 5) and the term would have to be in at least 5 of the documents to be considered. Here I pass 0.1; the term must be in at least 10% of the document.\n",
    "\n",
    "**ngram_range**: this just means I'll look at unigrams, bigrams and trigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenize = lambda text: text.split(\" \")\n",
    "stem = lambda token, stemmer=SnowballStemmer(\"english\"): stemmer.stem(token)\n",
    "tokenize_and_stem = lambda text: [stem(token) for token in tokenize(text)]\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_df = 0.8,\n",
    "    max_features = 200000,\n",
    "    min_df = 0.1,\n",
    "    stop_words = 'english',\n",
    "    use_idf = True,\n",
    "    tokenizer = tokenize_and_stem,\n",
    "    ngram_range = (1,3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The crawling proccess has been done in two different ways:\n",
    "\n",
    "- **No costraint**: the crawler follows a random outlink from all of the outlinks in a given page\n",
    "- **List costraint**: the crawler follows a random outlink but only from the outlinks in \"lists\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No-costraint documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nocostraint_path = os.getcwd() + \"/../dataset/\" + site + \"/no_constraint/words1000_depth10/\"\n",
    "vertex_nc_path   = nocostraint_path + \"vertex.txt\"\n",
    "map_nc_path      = nocostraint_path + \"urlsMap.txt\"\n",
    "\n",
    "codecontent_map_nc = get_content_map(vertex_nc_path)\n",
    "urlmap_nc          = get_urlmap(map_nc_path)\n",
    "\n",
    "documents_nc = [codecontent_map_nc[key] for key in codecontent_map_nc]\n",
    "codes_nc     = [key for key in codecontent_map_nc]\n",
    "urls_nc      = [urlmap_nc[key] for key in codecontent_map_nc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine-Similarity\n",
    "Cosine similarity is measured against the tf-idf matrix and can be used to generate a measure of similarity between each document and the other documents in the corpus.\n",
    "\n",
    "Subtracting it from 1 provides cosine distance which I will use for plotting on a euclidean (2-dimensional) plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = tfidf_matrix_nc.todense().tolist()\n",
    "type(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.52 s, sys: 81.9 ms, total: 7.6 s\n",
      "Wall time: 7.72 s\n",
      "              \n",
      "documents  728\n",
      "terms      433\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time tfidf_matrix_nc = tfidf_vectorizer.fit_transform(documents_nc)\n",
    "dist_nc = 1 - cosine_similarity(tfidf_matrix_nc)\n",
    "\n",
    "print(\n",
    "    pd.DataFrame(\n",
    "        {\"documents\": tfidf_matrix_nc.shape[0], \"terms\": tfidf_matrix_nc.shape[1]}, \n",
    "        index=[\"\"]\n",
    "    ).T\n",
    ")\n",
    "\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering on No-costraint documents\n",
    "#### K-Means\n",
    "\n",
    "K-means initializes with a pre-determined number of clusters. Each observation is assigned to a cluster (cluster assignment) so as to minimize the within cluster sum of squares. Next, the mean of the clustered observations is calculated and used as the new cluster centroid. Then, observations are reassigned to clusters and centroids recalculated in an iterative process until the algorithm reaches convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=30)\n",
    "%time kmeans_labels_nc = kmeans.fit_predict(tfidf_matrix_nc)\n",
    "\n",
    "docs_nc = { \n",
    "    'code': codes_nc,\n",
    "    'document': documents_nc\n",
    "}\n",
    "frame_nc = pd.DataFrame(docs_nc, index=[kmeans_labels_nc] , columns=['document', 'code'])\n",
    "\n",
    "frame_nc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic modeling\n",
    "Some fancy indexing and sorting on each cluster to identify which are the top n words that are nearest to the cluster centroid. This gives an idea of the main topic of each the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# map -> {code: token_list}\n",
    "tokens_nc_map = to_tokens_map(codecontent_map_nc)\n",
    "# map -> {code: stem_list}\n",
    "stems_nc_map = to_stems_map(codecontent_map_nc)\n",
    "\n",
    "# total vocabulary, list of tokens\n",
    "totalvocab_nc_stemmed = [stem for key in codecontent_map_nc for stem in stems_nc_map[key]]\n",
    "# total vocabulary, list of stems\n",
    "totalvocab_nc_tokenized = [stem for key in codecontent_map_nc for stem in tokens_nc_map[key]]\n",
    "\n",
    "vocab_nc_frame = pd.DataFrame({'words': totalvocab_nc_tokenized}, index = totalvocab_nc_stemmed)\n",
    "terms_nc = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# sort cluster centers by proximity to centroid\n",
    "order_centroids_nc = kmeans.cluster_centers_.argsort()[:,::-1]\n",
    "\n",
    "num_clusters_nc = len(set(kmeans_labels_nc))\n",
    "words_matrix_nc = [None] * num_clusters_nc\n",
    "top_n = 7\n",
    "\n",
    "for i in range(num_clusters_nc):\n",
    "    cluster_chart = [vocab_nc_frame.ix[terms_nc[ind].split(' ')].values.tolist()[0][0] \n",
    "                     for ind in order_centroids_nc[i,:top_n]]\n",
    "    words_matrix_nc[i] = cluster_chart\n",
    "    \n",
    "pd.DataFrame(\n",
    "    words_matrix_nc, \n",
    "    index = [\"Cluster \" + str(i) + \" - Top Words\" for i in range(num_clusters_nc)],\n",
    "    columns = list(range(1, top_n+1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Plot\n",
    "Applying t-SNE for dimensionality reduction. We need two dimensional vectors for visualization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%time tsne = TSNE(n_components=2, random_state=1)\n",
    "twodim_docs_nc = tsne.fit_transform(dist_nc)\n",
    "\n",
    "clusters_colors_nc = [ get_color(i) for i in kmeans_labels_nc]\n",
    "\n",
    "kmeans_data = scatter_plot(twodim_docs_nc, word_labels=urls_nc, colors=clusters_colors_nc)\n",
    "py.iplot(kmeans_data, filename=\"K-Means t-SNE nocostraint - Doc Clustering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <a href=\"https://plot.ly/~chrispolo/70\" \n",
    "        target=\"_blank\" title=\"y\" \n",
    "        style=\"display: block; text-align: center;\">\n",
    "            <img src=\"../dataset/img/nc_docs_wordvectors_scatter_plot_KMEANS.png\" \n",
    "                alt=\"y\" style=\"max-width: 100%;width: 1121px;\"  \n",
    "                width=\"100%\" onerror=\"this.onerror=null;this.src='https://plot.ly/404';\" />\n",
    "    </a>\n",
    "    <script data-plotly=\"chrispolo:70\"  src=\"https://plot.ly/embed.js\" async></script>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List-costraint documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "listcostraint_path = os.getcwd() + \"/../dataset/\" + site + \"/list_constraint/words1000_depth10/\"\n",
    "vertex_lc_path     = listcostraint_path + \"vertex.txt\"\n",
    "map_lc_path        = listcostraint_path + \"urlsMap.txt\"\n",
    "\n",
    "codecontent_map_lc = get_content_map(vertex_lc_path)\n",
    "urlmap_lc = get_urlmap(map_lc_path)\n",
    "\n",
    "# document list\n",
    "documents_lc = [codecontent_map_lc[key] for key in codecontent_map_lc]\n",
    "codes_lc     = [key for key in codecontent_map_lc]\n",
    "urls_lc      = [urlmap_lc[key] for key in codecontent_map_lc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine-Similarity\n",
    "Cosine similarity is measured against the tf-idf matrix and can be used to generate a measure of similarity between each document and the other documents in the corpus.\n",
    "\n",
    "Subtracting it from 1 provides cosine distance which I will use for plotting on a euclidean (2-dimensional) plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time tfidf_matrix_lc = tfidf_vectorizer.fit_transform(documents_lc)\n",
    "\n",
    "dist_lc = 1 - cosine_similarity(tfidf_matrix_lc)\n",
    "\n",
    "print(pd.DataFrame({\"documents\":tfidf_matrix_lc.shape[0], \"terms\":tfidf_matrix_lc.shape[1]}, index=[\"\"]).T)\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering on List-costraint documents\n",
    "#### K-Means\n",
    "K-means initializes with a pre-determined number of clusters. Each observation is assigned to a cluster (cluster assignment) so as to minimize the within cluster sum of squares. Next, the mean of the clustered observations is calculated and used as the new cluster centroid. Then, observations are reassigned to clusters and centroids recalculated in an iterative process until the algorithm reaches convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=25)\n",
    "%time kmeans_labels_lc = kmeans.fit_predict(tfidf_matrix_lc)\n",
    "docs_lc = {\n",
    "    'code': codes_lc,\n",
    "    'document': documents_lc\n",
    "}\n",
    "\n",
    "frame_lc = pd.DataFrame(docs_lc, index = [kmeans_labels_lc] , columns = ['document', 'code'])\n",
    "frame_lc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic modeling\n",
    "Some fancy indexing and sorting on each cluster to identify which are the top n words that are nearest to the cluster centroid. This gives an idea of the main topic of each the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# map -> {code: token_list}\n",
    "tokens_lc_map = to_tokens_map(codecontent_map_lc)\n",
    "# map -> {code: stem_list}\n",
    "stems_lc_map = to_stems_map(codecontent_map_lc)\n",
    "\n",
    "# total vocabulary, list of tokens\n",
    "totalvocab_lc_stemmed = [stem for key in codecontent_map_lc for stem in stems_lc_map[key]]\n",
    "# total vocabulary, list of stems\n",
    "totalvocab_lc_tokenized = [stem for key in codecontent_map_lc for stem in tokens_lc_map[key]]\n",
    "\n",
    "vocab_lc_frame = pd.DataFrame({'words': totalvocab_lc_tokenized}, index = totalvocab_lc_stemmed)\n",
    "terms_lc = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# sort cluster centers by proximity to centroid\n",
    "order_centroids_lc = kmeans.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "num_clusters_lc = len(set(kmeans_labels_lc))\n",
    "words_matrix_lc = [None] * num_clusters_lc\n",
    "top_n = 7\n",
    "\n",
    "for i in range(num_clusters_lc):\n",
    "    cluster_chart = [vocab_lc_frame.ix[terms_lc[ind].split(' ')].values.tolist()[0][0] for ind in order_centroids_lc[i,:top_n]]\n",
    "    words_matrix_lc[i] = cluster_chart\n",
    "    \n",
    "pd.DataFrame(\n",
    "    words_matrix_lc, \n",
    "    index = [\"Cluster \" + str(i) + \" - Top Words\" for i in range(num_clusters_lc)],\n",
    "    columns = list(range(1, top_n+1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Plot\n",
    "Applying t-SNE for dimensionality reduction. We need two dimensional vectors for visualization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state=1)\n",
    "twodim_docs_lc = tsne.fit_transform(dist_lc)\n",
    "\n",
    "clusters_colors_lc = [ get_color(i) for i in kmeans_labels_lc]\n",
    "\n",
    "k_tsne_data_lc = scatter_plot(twodim_docs_lc, word_labels=urls_lc, colors=clusters_colors_lc)\n",
    "py.iplot(k_tsne_data_lc, filename=\"K-Means listcostraint - Doc Clustering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <a href=\"https://plot.ly/~chrispolo/74\" \n",
    "        target=\"_blank\" title=\"y\" \n",
    "        style=\"display: block; text-align: center;\">\n",
    "            <img src=\"../dataset/img/lc_docs_wordvectors_scatter_plot_KMEANS.png\" \n",
    "                alt=\"y\" style=\"max-width: 100%;width: 1121px;\"  \n",
    "                width=\"100%\" onerror=\"this.onerror=null;this.src='https://plot.ly/404';\" />\n",
    "    </a>\n",
    "    <script data-plotly=\"chrispolo:74\"  src=\"https://plot.ly/embed.js\" async></script>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Evaluating the performance of a clustering algorithm is not as trivial as counting the number of errors or the precision and recall of a supervised classification algorithm. In particular any evaluation metric should not take the absolute values of the cluster labels into account but rather if this clustering define separations of the data similar to some ground truth set of classes or satisfying some assumption such that members belong to the same class are more similar that members of different classes according to some similarity metric.\n",
    "\n",
    "See the [scikit-learn documentaion](http://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation \"ti\") for futher information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gt = GroundTruth(os.getcwd() + \"/../dataset/\" + site + \"/ground_truth/urlToMembership.txt\")\n",
    "ground_truth_lc = [int(gt.get_groundtruth(urlmap_lc[key])) for key in codecontent_map_lc]\n",
    "\n",
    "gt = GroundTruth(os.getcwd() + \"/../dataset/\" + site + \"/ground_truth/urlToMembership.txt\")\n",
    "ground_truth_nc = [int(gt.get_groundtruth(urlmap_nc[key])) for key in codecontent_map_nc]\n",
    "\n",
    "print(\"Clusters found manually for no-costraint documents:\", len(set(ground_truth_nc)))\n",
    "print([label for label in set(ground_truth_nc)])\n",
    "print()\n",
    "print(\"Clusters found manually for list-costraint documents:\", len(set(ground_truth_lc)))\n",
    "print([label for label in set(ground_truth_lc)])\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN and HDBSCAN\n",
    "Applying other clustering algorithm for evaluation purposes.\n",
    "\n",
    "**DBSCAN** - Density-Based Spatial Clustering of Applications with Noise. Finds core samples of high density and expands clusters from them. Good for data which contains clusters of similar density.\n",
    "\n",
    "**params**:\n",
    "\n",
    "- **eps** : The maximum distance between two samples for them to be considered as in the same neighborhood.\n",
    "- **min_samples** : The number of samples (or total weight) in a neighborhood for a point to be considered as a core point. This includes the point itself.\n",
    "\n",
    "\n",
    "**HDBSCAN** - Hierarchical Density-Based Spatial Clustering of Applications with Noise. Performs DBSCAN over varying epsilon values and integrates the result to find a clustering that gives the best stability over epsilon. This allows HDBSCAN to find clusters of varying densities (unlike DBSCAN), and be more robust to parameter selection.\n",
    "\n",
    "**params**:\n",
    "\n",
    "- **min_cluster_size** : minimum nodes to form a cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  No-costraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=0.3, min_samples=5)\n",
    "%time dbscan_labels_nc = dbscan.fit_predict(tfidf_matrix_nc)\n",
    "\n",
    "print(\"Clusters found with DBSCAN:\", len(set(dbscan_labels_nc)))\n",
    "print ([label for label in set(dbscan_labels_nc)])\n",
    "print(\"\\n\")\n",
    "\n",
    "hdbscan = HDBSCAN(min_cluster_size=15)\n",
    "%time hdbscan_labels_nc = hdbscan.fit_predict(tfidf_matrix_nc)\n",
    "\n",
    "print(\"Clusters found with HDBSCAN:\", len(set(hdbscan_labels_nc)))\n",
    "print([label for label in set(hdbscan_labels_nc)])\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List-costraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=0.7, min_samples=7)\n",
    "%time dbscan_labels_lc = dbscan.fit_predict(tfidf_matrix_lc)\n",
    "\n",
    "print(\"Clusters found with DBSCAN:\", len(set(dbscan_labels_lc)))\n",
    "print ([label for label in set(dbscan_labels_lc)])\n",
    "print(\"\\n\")\n",
    "\n",
    "hdbscan = HDBSCAN(min_cluster_size=7)\n",
    "%time hdbscan_labels_lc = hdbscan.fit_predict(tfidf_matrix_lc)\n",
    "\n",
    "print(\"Clusters found with HDBSCAN:\", len(set(hdbscan_labels_lc)))\n",
    "print([label for label in set(hdbscan_labels_lc)])\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics:\n",
    "\n",
    "- **Homogeneity**: each cluster contains only members of a single class\n",
    "\n",
    "\n",
    "- **Completeness**: all members of a given class are assigned to the same cluster\n",
    "\n",
    "\n",
    "- **Adjusted Rand index**: Given the knowledge of the *ground truth* class assignments and our clustering algorithm assignments of the same samples, the adjusted Rand index is a function that measures the similarity of the two assignments, ignoring permutations and with chance normalization\n",
    "\n",
    "\n",
    "- **V-measure**: The V-measure is actually equivalent to the mutual information (NMI) discussed above normalized by the sum of the label entropies\n",
    "\n",
    "\n",
    "- **Mutual Information based scores**: Given the knowledge of the ground truth class assignments and our clustering algorithm assignments of the same samples, the Mutual Information is a function that measures the agreement of the two assignments, ignoring permutations. Two different normalized versions of this measure are available, Normalized Mutual Information(NMI) and Adjusted Mutual Information(AMI). NMI is often used in the literature while AMI was proposed more recently and is normalized against chance\n",
    "\n",
    "\n",
    "- **Silhouette**: If the ground truth labels are not known, evaluation must be performed using the model itself. The Silhouette Coefficient is an example of such an evaluation, where a higher Silhouette Coefficient score relates to a model with better defined clusters. The score is bounded between -1 for incorrect clustering and +1 for highly dense clustering. Scores around zero indicate overlapping clusters. The score is higher when clusters are dense and well separated, which relates to a standard concept of a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame([\n",
    "        [\n",
    "            # dbscan nocostraint\n",
    "            metrics.homogeneity_score(ground_truth_nc, dbscan_labels_nc),\n",
    "            metrics.completeness_score(ground_truth_nc, dbscan_labels_nc),\n",
    "            metrics.v_measure_score(ground_truth_nc, dbscan_labels_nc),\n",
    "            metrics.adjusted_rand_score(ground_truth_nc, dbscan_labels_nc),\n",
    "            metrics.adjusted_mutual_info_score(ground_truth_nc, dbscan_labels_nc),\n",
    "            metrics.silhouette_score(tfidf_matrix_nc, dbscan_labels_nc, metric='euclidean')\n",
    "        ],\n",
    "        [\n",
    "            # hdbscan nocostraint\n",
    "            metrics.homogeneity_score(ground_truth_nc, hdbscan_labels_nc),\n",
    "            metrics.completeness_score(ground_truth_nc, hdbscan_labels_nc),\n",
    "            metrics.v_measure_score(ground_truth_nc, hdbscan_labels_nc),\n",
    "            metrics.adjusted_rand_score(ground_truth_nc, hdbscan_labels_nc),\n",
    "            metrics.adjusted_mutual_info_score(ground_truth_nc, hdbscan_labels_nc),\n",
    "            metrics.silhouette_score(tfidf_matrix_nc, hdbscan_labels_nc, metric='euclidean')\n",
    "        ],\n",
    "        [\n",
    "            # kmeans nocostraint\n",
    "            metrics.homogeneity_score(ground_truth_nc, kmeans_labels_nc),\n",
    "            metrics.completeness_score(ground_truth_nc, kmeans_labels_nc),\n",
    "            metrics.v_measure_score(ground_truth_nc, kmeans_labels_nc),\n",
    "            metrics.adjusted_rand_score(ground_truth_nc, kmeans_labels_nc),\n",
    "            metrics.adjusted_mutual_info_score(ground_truth_nc, kmeans_labels_nc),\n",
    "            metrics.silhouette_score(tfidf_matrix_nc, kmeans_labels_nc, metric='euclidean')\n",
    "        ],\n",
    "        [\n",
    "            # dbscan listcostraint\n",
    "            metrics.homogeneity_score(ground_truth_lc, dbscan_labels_lc),\n",
    "            metrics.completeness_score(ground_truth_lc, dbscan_labels_lc),\n",
    "            metrics.v_measure_score(ground_truth_lc, dbscan_labels_lc),\n",
    "            metrics.adjusted_rand_score(ground_truth_lc, dbscan_labels_lc),\n",
    "            metrics.adjusted_mutual_info_score(ground_truth_lc, dbscan_labels_lc),\n",
    "            metrics.silhouette_score(tfidf_matrix_lc, dbscan_labels_lc, metric='euclidean')\n",
    "        ],\n",
    "        [\n",
    "            # hdbscan listcostraint\n",
    "            metrics.homogeneity_score(ground_truth_lc, hdbscan_labels_lc),\n",
    "            metrics.completeness_score(ground_truth_lc, hdbscan_labels_lc),\n",
    "            metrics.v_measure_score(ground_truth_lc, hdbscan_labels_lc),\n",
    "            metrics.adjusted_rand_score(ground_truth_lc, hdbscan_labels_lc),\n",
    "            metrics.adjusted_mutual_info_score(ground_truth_lc, hdbscan_labels_lc),\n",
    "            metrics.silhouette_score(tfidf_matrix_lc, hdbscan_labels_lc, metric='euclidean')\n",
    "        ],\n",
    "        [\n",
    "            # kmeans listcostraint\n",
    "            metrics.homogeneity_score(ground_truth_lc, kmeans_labels_lc),\n",
    "            metrics.completeness_score(ground_truth_lc, kmeans_labels_lc),\n",
    "            metrics.v_measure_score(ground_truth_lc, kmeans_labels_lc),\n",
    "            metrics.adjusted_rand_score(ground_truth_lc, kmeans_labels_lc),\n",
    "            metrics.adjusted_mutual_info_score(ground_truth_lc, kmeans_labels_lc),\n",
    "            metrics.silhouette_score(tfidf_matrix_lc, kmeans_labels_lc, metric='euclidean')\n",
    "        ]],\n",
    "        index=[\n",
    "            \"NoCostraint - DBSCAN\", \n",
    "            \"NoCostraint - HDBSCAN\", \n",
    "            \"NoCostraint - K-MEANS\", \n",
    "            \"ListCostraint - DBSCAN\", \n",
    "            \"ListCostraint - HDBSCAN\", \n",
    "            \"ListCostraint - K-MEANS\"\n",
    "        ],\n",
    "        columns=[\n",
    "            \"Homogeneity\", \n",
    "            \"Completeness\", \n",
    "            \"V-Measure score\", \n",
    "            \"Adjusted Rand index\", \n",
    "            \"Mutual Information\",\n",
    "            \"Silhouette\"\n",
    "        ])\n",
    "\n",
    "metrics_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
