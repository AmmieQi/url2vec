{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from sklearn import metrics\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from gensim.models import Word2Vec\n",
    "from url2vec.util.metrics import *\n",
    "from url2vec.util.plotter import *\n",
    "from url2vec.model.urlembed import *\n",
    "from url2vec.util.seqmanager import *\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nocostraint_path = os.getcwd() + \"/../dataset/cs.illinois.edu_ListConstraint.words1000.depth10/\"\n",
    "\n",
    "vertex_path      = nocostraint_path + \"vertex.txt\"\n",
    "codecontent_map  = get_content_map(vertex_path)\n",
    "\n",
    "map_path         = nocostraint_path + \"urlsMap.txt\"\n",
    "codeurl_map      = get_urlmap(map_path)\n",
    "\n",
    "sequences        = nocostraint_path + \"sequenceIDs.txt\"\n",
    "seq              = get_sequences(sequences)\n",
    "\n",
    "gt = GroundTruth()\n",
    "ground_truth = [int(gt.get_groundtruth(codeurl_map[code])) for code in codeurl_map]\n",
    "\n",
    "url2vec = Url2Vec(codeurl_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = u2v.train(sequences_list=seq, codecontent_map=codecontent_map)\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(u2v.test(ground_truth), index=set(ground_truth), columns=set(labels))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nocostraint_path = os.getcwd() + \"/../dataset/new/cs.illinois.edu.ListConstraint.words1000.depth10/\"\n",
    "rmfile  = \"/home/chris/workspace/jupyter-notebook/url2vec/dataset/manual-membership/urlToMembership.txt\"\n",
    "vertex_path      = nocostraint_path + \"vertex.txt\"\n",
    "map_path         = nocostraint_path + \"urlsMap.txt\"\n",
    "sequences        = nocostraint_path + \"sequenceIDs.txt\"\n",
    "\n",
    "urlmap = get_urlmap(map_path)\n",
    "\n",
    "u2v  = Url2Vec(urlmap)\n",
    "u2v2 = Url2Vec(urlmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq = get_sequences(sequences)\n",
    "codecontent_map = get_content_map(vertex_path)\n",
    "\n",
    "k_memb = u2v.train(algorithm=KMeans(n_clusters=15), sequences_list=seq, codecontent_map=codecontent_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq2 = get_sequences(sequences)\n",
    "hd_memb = u2v2.train(sequences_list=seq2, codecontent_map=codecontent_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gt = GroundTruth(rmfile)\n",
    "ground_truth = [int(gt.get_groundtruth(codeurl_map[code])) for code in codeurl_map]\n",
    "\n",
    "confusion_table = u2v.test(ground_truth)\n",
    "pd.DataFrame(confusion_table, index=set(ground_truth), columns=set(u2v.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "confusion_table_hdbscan = u2v2.test(ground_truth)\n",
    "pd.DataFrame(confusion_table_hdbscan, index=set(ground_truth), columns=set(u2v2.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# k_memb  \n",
    "labels_pred_k = map(int, k_memb)\n",
    "labels_pred_h = hd_memb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Homogeneity:\\t\\t\", metrics.homogeneity_score(ground_truth, labels_pred_k)\n",
    "print \"Completeness:\\t\\t\", metrics.completeness_score(ground_truth, labels_pred_k)\n",
    "print \"V Measure Score:\\t\", metrics.v_measure_score(ground_truth, labels_pred_k)\n",
    "print \"adjusted rand score:\\t\", metrics.adjusted_rand_score(ground_truth, labels_pred_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Homogeneity:\\t\\t\", metrics.homogeneity_score(ground_truth, labels_pred_h) # best 1\n",
    "print \"Completeness:\\t\\t\", metrics.completeness_score(ground_truth, labels_pred_h)  # best 1\n",
    "print \"V Measure Score:\\t\", metrics.v_measure_score(ground_truth, labels_pred_h) # best 1\n",
    "print \"adjusted rand score:\\t\", metrics.adjusted_rand_score(ground_truth, labels_pred_h) # best 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
