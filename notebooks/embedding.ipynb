{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#import csv\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from urlembed.util.seqmanager import *\n",
    "from urlembed.util.plotter import *\n",
    "from urlembed.util.metrics import *\n",
    "\n",
    "# import sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "import hdbscan\n",
    "\n",
    "# import plotly\n",
    "import plotly.plotly as py\n",
    "# import plotly.graph_objs as go\n",
    "from plotly.graph_objs import *\n",
    "from plotly.tools import FigureFactory as FF\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORD2VEC MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nocostraint_path = os.getcwd() + \"/../dataset/cs.illinois.edu_NoConstraint.words1000.depth10/\"\n",
    "nocostraint_urlmap_path = nocostraint_path + \"urlsMap.txt\"\n",
    "nocostraint_seq_path = nocostraint_path + \"sequenceIDs.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "994570"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# because of generator\n",
    "vocab_sequences = get_sequences(nocostraint_seq_path)\n",
    "train_sequences = get_sequences(nocostraint_seq_path)\n",
    "\n",
    "w2v_model = Word2Vec(min_count=1, window=5, negative=5)\n",
    "w2v_model.build_vocab(vocab_sequences)\n",
    "w2v_model.train(train_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE 2-DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nocostraint_urlmap = get_urlmap(nocostraint_urlmap_path)\n",
    "\n",
    "# 100-dim vecs\n",
    "wordvecs_nc = np.array([w2v_model[key] for key in nocostraint_urlmap], dtype=\"float64\")\n",
    "# hundred_dim_wordvecs = np.array(wordvecs, dtype=\"float64\")\n",
    "\n",
    "# URL labels\n",
    "urls = [nocostraint_urlmap[key] for key in nocostraint_urlmap]\n",
    "\n",
    "# 2-dim vecs\n",
    "tsne = TSNE(n_components=2)\n",
    "twodim_wordvecs_nc = tsne.fit_transform(wordvecs_nc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters found with DBSCAN: 19\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, -1]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dbscan_clusterer = DBSCAN(eps=0.9, min_samples=4)\n",
    "dbscan_clusterer.fit(wordvecs_nc)\n",
    "\n",
    "dbscan_colors_nc = [get_color(clust) for clust in dbscan_clusterer.labels_]\n",
    "\n",
    "print(\"Clusters found with DBSCAN:\", len(set(dbscan_clusterer.labels_)))\n",
    "print ([label for label in set(dbscan_clusterer.labels_)])\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dbscan_data = scatter_plot(twodim_wordvecs_nc, urls, dbscan_colors_nc)\n",
    "py.iplot(dbscan_data, filename='Word Vectors - Scatter plot DBSCAN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <a href=\"https://plot.ly/~chrispolo/0\" \n",
    "        target=\"_blank\" title=\"y\" \n",
    "        style=\"display: block; text-align: center;\">\n",
    "            <img src=\"../dataset/img/wordvectors_scatter_plot_DBSCAN.png\" \n",
    "                alt=\"y\" style=\"max-width: 100%;width: 1121px;\"  \n",
    "                width=\"100%\" onerror=\"this.onerror=null;this.src='https://plot.ly/404';\" />\n",
    "    </a>\n",
    "    <script data-plotly=\"chrispolo:0\"  src=\"https://plot.ly/embed.js\" async></script>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDBSCAN CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters found with HDBSCAN: 13\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, -1]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hdbscan_clusterer = hdbscan.HDBSCAN(min_cluster_size=6)\n",
    "hdbscan_labels = hdbscan_clusterer.fit_predict(wordvecs_nc)\n",
    "\n",
    "hdbscan_colors_nc = [get_color(clust) for clust in hdbscan_labels]\n",
    "\n",
    "print(\"Clusters found with HDBSCAN:\", len(set(hdbscan_labels)))\n",
    "print([label for label in set(hdbscan_labels)])\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDBSCAN PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hdbscan_data = scatter_plot(twodim_wordvecs_nc, urls, hdbscan_colors_nc)\n",
    "py.iplot(hdbscan_data, filename='Word Vectors - Scatter plot HDBSCAN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <a href=\"https://plot.ly/~chrispolo/2\" \n",
    "        target=\"_blank\" title=\"y\" \n",
    "        style=\"display: block; text-align: center;\">\n",
    "            <img src=\"../dataset/img/wordvectors_scatter_plot_HDBSCAN.png\" \n",
    "                alt=\"y\" style=\"max-width: 100%;width: 1121px;\"  \n",
    "                width=\"100%\" onerror=\"this.onerror=null;this.src='https://plot.ly/404';\" />\n",
    "    </a>\n",
    "    <script data-plotly=\"chrispolo:2\"  src=\"https://plot.ly/embed.js\" async></script>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-MEANS CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters found with K-MEANS: 15\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=15)\n",
    "kmeans.fit(wordvecs_nc)\n",
    "\n",
    "kmeans_colors_nc = [get_color(clust) for clust in kmeans.labels_]\n",
    "\n",
    "print(\"Clusters found with K-MEANS:\", len(set(kmeans.labels_)))\n",
    "print([label for label in set(kmeans.labels_)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-MEANS PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kmeans_data = scatter_plot(twodim_wordvecs_nc, urls, kmeans_colors_nc)\n",
    "py.iplot(kmeans_data, filename='Word Vectors - Scatter plot K-MEANS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <a href=\"https://plot.ly/~chrispolo/4\" \n",
    "        target=\"_blank\" title=\"y\" \n",
    "        style=\"display: block; text-align: center;\">\n",
    "            <img src=\"../dataset/img/wordvectors_scatter_plot_KMEANS.png\" \n",
    "                alt=\"y\" style=\"max-width: 100%;width: 1121px;\"  \n",
    "                width=\"100%\" onerror=\"this.onerror=null;this.src='https://plot.ly/404';\" />\n",
    "    </a>\n",
    "    <script data-plotly=\"chrispolo:4\"  src=\"https://plot.ly/embed.js\" async></script>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MANUALLY CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters found manually: 14\n",
      "[0, 1, 2, 3, 4, 6, 8, 10, 11, 12, 13, 14, 15, -1]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"clusterized_map_path = nopath + \"sequencesMapUrl-manually-clusterized.txt\"\n",
    "seq_tuple_list = get_sequence_tuple_list(clusterized_map_path)\n",
    "\"\"\"\n",
    "gt = GroundTruth(os.getcwd() + \"/../dataset/ground_truth/urlToMembership.txt\")\n",
    "ground_truth = [int(gt.get_groundtruth(nocostraint_urlmap[key])) for key in nocostraint_urlmap]\n",
    "\"\"\"\n",
    "# dict{url_code: cluster_membership} - manually clusterized\n",
    "real_cluster_membership = {tup[1].strip(): int(tup[2].strip()) for tup in seq_tuple_list}\n",
    "\n",
    "# dict{longurl: cluster_membership} - manually clusterized - never used\n",
    "real_cluster_longurl_membership = {tup[0].strip(): int(tup[2].strip()) for tup in seq_tuple_list}\n",
    "\"\"\"\n",
    "real_colors = [get_color(n) for n in ground_truth]\n",
    "\n",
    "print(\"Clusters found manually:\", len(set(ground_truth)))\n",
    "print([label for label in set(ground_truth)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MANUALLY CLUSTERING - PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "groundtruth_data = scatter_plot(twodim_wordvecs_nc, urls, real_colors)\n",
    "py.iplot(groundtruth_data, filename='Word Vectors - Scatter plot Ground Truth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <a href=\"https://plot.ly/~chrispolo/56\" \n",
    "        target=\"_blank\" title=\"y\" \n",
    "        style=\"display: block; text-align: center;\">\n",
    "            <img src=\"../dataset/img/wordvectors_scatter_plot_GROUNDTRUTH.png\" \n",
    "                alt=\"y\" style=\"max-width: 100%;width: 1121px;\"  \n",
    "                width=\"100%\" onerror=\"this.onerror=null;this.src='https://plot.ly/404';\" />\n",
    "    </a>\n",
    "    <script data-plotly=\"chrispolo:56\"  src=\"https://plot.ly/embed.js\" async></script>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# using seq_map to keep the same order, dunno if it's right\n",
    "real_membership_list = [real_cluster_membership[key] for key in seq_map]\n",
    "    \n",
    "real_membership_list = np.array(real_membership_list, dtype=\"int32\")\n",
    "\n",
    "print \"precision: \", sklearn.metrics.precision_score(real_membership_list, kmeans_clusters.labels_)\n",
    "print \"recall:    \", sklearn.metrics.recall_score(real_membership_list, kmeans_clusters.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_confusion_table(real_membership_list, clusters_found_labels):\n",
    "    # matrix(num_of real_clusters x clusters_found)\n",
    "    conf_table = np.zeros((len(set(real_membership_list)), len(set(clusters_found_labels))), dtype=\"int32\")\n",
    "    \n",
    "    real_clusters_set = set(real_membership_list)\n",
    "    \n",
    "    for current_clust in real_clusters_set:\n",
    "        for i in range(len(clusters_found_labels)):\n",
    "            if real_membership_list[i] == current_clust:\n",
    "                cluster_found = clusters_found_labels[i]\n",
    "                conf_table[current_clust][cluster_found] = conf_table[current_clust][cluster_found] + 1\n",
    "    return conf_table\n",
    "\n",
    "C = kmeans_clusterer.labels_\n",
    "\n",
    "confusion_table = get_confusion_table(real_membership_list, C)\n",
    "\n",
    "print set(real_membership_list), set(C)\n",
    "print confusion_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
